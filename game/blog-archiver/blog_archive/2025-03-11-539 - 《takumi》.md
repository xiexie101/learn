---
title: "539 - 《takumi》"
date: 2025-03-11
url: https://sorrycc.com/takumi
---

发布于 2025年3月11日

# 539 - 《takumi》

> 注：takumi 寓意是日语的「匠」，たくみ，读着比较顺耳，污秘也有一点点字面上的关联。 但他是一个临时的命名，后面可能会调整。

1、Why takumi？

基于 [531 - 《AI x 程序员 x 蚂蚁》](https://sorrycc.com/ai-x-programmer-x-ant) 所说，以及我最近在使用 AI 工具上的体验，我觉得 AI 对于程序员的效率提升是非常大的。社区上已经有很多很好的例子，像是 Cursor、Cline、WindSurf 等。借助好的工具以及强大的模型，能够让程序员的编码效率得到极大的提升。

因此，我想把这一套方案也挪到内部来。内部出于数据安全的考虑，不能直接接入世界上最好的模型。但是，今年 DeepSeek 的出现让我们看到了希望。因为在有好工具的前提下，已经可以有一个还不错的输出和效果。同时，模型的迭代速度会很快，所以我觉得我们先准备好工具再等待模型迭代也是一个不错的选择。

很多人可能会觉得编辑器是使用 AI 提效编程的唯一途径，但其实并不是。像 Cli、客户端，甚至浏览器也都是可以选择的途径,只是体验上会有所不同，所拿到的上下文存在差异，交互方式会有不同。 用 Cli 做入口，社区已经有一些好的例子，像 Claude Code，以及 Aider 等。

takumi 我计划是先以 CLI 的方式去实现，后续再看我们是否需要增加新的入口，像 VSCode 编辑器插件之类的形式。

2、Cli 的优缺点。

Cli 的缺点我觉得是它的交互没有编辑器来得更丰富。没有图形界面来得更丰富。它也没有办法获取到编辑器相关的很多上下文信息，比如你当前打开的文件、Problem 面板的错误信息、lint 警告信息等。

但是 Cli 也有好处。我觉得它的好处就是更加灵活。比如可以把 Cli 作为工作流的一环，通过编程或者命令组合的方式去运行、去自动化。

我们也可以进一步扩展更多的需求，甚至做插件化。比如 Claude Code 有一个 init 的命令，可以基于你分析现有项目的代码结构、代码风格以及依赖，然后形成一个比较完善的关于你项目的描述。这个描述可以后续提供给大模型。

还有像 Aider 里有个 watch 模式。当你在编码时，在你的注释里面加上特殊的标记，比如 `AI!`，他会监听这个文件，针对这段描述直接执行任务并修改你的代码。我个人很喜欢这个功能。

3、takumi 是什么？

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/O0vv7o.png)

takumi 是一个 CLI 形式的 Code Agent。它所做的事和 Cursor 里面的 Agent 模式是类似的。它类似于 Claude Code 以及 Aider 。

目前已经完成了一个 MVP 的版本，可以把流程跑通。他支持我所用到过的所有的 provider 和好用的模型。他内置了一些工具，可以去新增和编辑文件、搜索文件内容、执行 bash 命令，做一些 Think 和 Architect 之类的事情，以及支持 MCP Server（注：MCP Server 的配置基于 JSON，和 Cursor 的一致），以及还有内置代码风格、README、Git 信息、目录结构等上下文信息。

一键上手（如果没有 Groq 的 API Key，先去[申请一个](https://console.groq.com/keys)，免费）。

```bash
GROQ_API_KEY=gsk_xxxx npx -y takumi --model=Groq/qwen-qwq-32b "create a.txt with some romantic text"
```

以下是一些例子。

> create a.txt with some romantic text

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/0JbgAt.png)

> create todo.html with a single file including a simple todo list app

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/GOjesT.png)

> how old is 赵本山（他会用 brave search 的 MCP Server 去搜索）

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/2gxet7.png)

> TODO：补充更多。

4、takumi 的下一步。

会有很多可以做的事情，目前想到的部分短期计划是这些。

一个是内部 DeepSeek 模型的验证，看它是否支持 function call。因为我用下来，其实所有的 DeepSeek 的服务基本上我都试过一遍。Function Call 只有字节豆包的 DeepSeek 是 Chat 和 R1 都支持的，我不知道为什么，同样都是满血版的 DeepSeek。如果验证下来内部的不支持 Function Call，那我们可能就要换一种方式去做，像 Cline 一样，返回结构化的数据，再基于结构化的数据去执行 Tools，这需要一些额外的工作。

以下是过程中手动记录的各个 provider 和模型的 function call 支持情况。

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/mhUJjB.png)

第二个是边界场景的覆盖。现在为了快速实现，没有去处理很多的边界场景以及异常，这个需要补全。

再有，我想做一个 Plan Mode。通常编码时，你时不能一下子把所有的问题都想清楚和制定非常详细的执行计划的，比如整体的方案是什么，比如怎么一步一步实现，比如使用哪些依赖库，比如用这些编辑的场景需要处理等等。有一个 Plan Mode，就可以让模型去辅助你把这些问题都想清楚，产出一份完整详尽的实施文档。当你确认完这份方案之后，再让 Code Agent 去帮你做具体的实施，就会容易很多。

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/qwNvvN.png)

其他的比如。比如说区分小模型和大模型，让小模型去处理简单任务，让大模型去处理复杂的任务。这样能够减少模型的消耗，并且提升速度。比如增加一个 VCR 的模式去记录完整的一个实施的过程，让开发者能够知道这底下详细的执行过程，也方便维护者去调试。比如前面提到的 AIDER 的 Watch 模式。

参考：  
[531 - 《AI x 程序员 x 蚂蚁》](https://sorrycc.com/ai-x-programmer-x-ant)

---
title: "439 - 《笔记：从前端到 AI：LangChain.js 入门和实战（1）》"
date: 2024-05-11
url: https://sorrycc.com/langchain-practice-01
---

发布于 2024年5月11日

# 439 - 《笔记：从前端到 AI：LangChain.js 入门和实战（1）》

> 本文是掘金课程的阅读笔记，看了感觉还不错，查漏补缺吧。课程链接见： [https://s.juejin.cn/ds/i2531au3/](https://s.juejin.cn/ds/i2531au3/) 。

1、用 Deno + [Jupyter Notebook](https://jupyter.org/) 调参数和 prompt，相比 Node 程序每次改完后要重头跑会简单不少，[示例](https://github.com/RealKai42/langchainjs-juejin/blob/main/learn-notebook-basic.ipynb)。而用 Deno 的好处是不需要安装依赖，Deno 运行时会自动安装。VSCode 下用 Jupyter 安装个 [Jupyter VSCode 插件](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) 会有高亮。

2、如果没有 OpenAI 官方的 API，其他可选服务包括 Azure OpenAI、第三方中转、本地大模型。本地大模型作者推荐了 [ollama](https://ollama.com/)，可以下载 7B 的版本，本地测试够用。

OpenAI 示例。

```ts
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage } from "@langchain/core/messages";

let chatModel = new ChatOpenAI({
  configuration: {
    // 使用三方中转时需要制定
    baseURL: '',
  },
});
await chatModel.invoke([
  new HumanMessage("Tell me a joke"),
]);
```

本地 ollama 大模型。

```ts
import { Ollama } from "@langchain/community/llms/ollama";

let ollama = new Ollama({
  baseUrl: "http://localhost:11434", 
  model: "llama2", 
});
let res = await ollama.invoke("讲个笑话");
```

3、langchain 由于历史原因，有多套设计，导致用户写法也会不同。其中 LCEL（LangChain Expression Language）是  
langchain 主推的新设计，其好处是从原型到生产的完整流程不需要修改任何代码就能支持生产级别的各种特性，比如并行、自动的重试和 fallback、对 chain 中间结果的访问、LangSimith 可视化、steaming 等。

一条 Chain 上的每个模块都继承自 Runnable，常用有 invoke、batch、stream 和 streamLog 四个方法。Runnable 之间可通过 `.pipe()` 串起来。

```ts
let chatModel = new ChatOpenAI();
let outputPrase = new StringOutputParser();
let chain = chatModel.pipe(outputPrase);
// invoke
await chain.invoke([
  new HumanMessage("Tell me a joke")
]);
// batch
await chain.batch([
  [new HumanMessage("Tell me a joke")],
  [new HumanMessage("Hi, Who are you?")],
]);
// stream
let stream = await simpleChain.stream([ new HumanMessage("Tell me a joke") ]);
for await (let chunk of stream) {
  console.log(chunk);
}
// fallback
chain = chain.withFallbacks({
  fallbacks: [new ChatOpenAI()],
});
```

4、RAG 全称 Retrieval（检索） Augmented（增强） Generation（生成）。RAG 解两个问题，1）幻觉（hallucination），2）领域知识的欠缺。RAG 的基本流程是加载、切分、嵌入、检索、prompt，我去年搞过的 [285 - 《minicc 和 OpenAI embedding》](https://sorrycc.com/minicc) 就是这种。

5、PromptTemplate 可以让我们以工程化的方式管理和构建 prompt。除了 PromptTemplate，还有 ChatPromptTemplate、SystemMessagePromptTemplate、AIMessagePromptTemplate 和 HumanMessagePromptTemplate，后三个分别对应 system、assistant 和 user 三个角色。还有个更高级的 PipelinePromptTemplate，感觉没啥必要。

```ts
import { PromptTemplate } from "@langchain/core/prompts";

// create
let tpl = new PromptTemplate({
  inputVariables: ["world", "name"],
  template: "hello {world}，{name}",
});
// or
let tpl = PromptTemplate.fromTemplate("hello {world}, {name}");

// use
let prompt = await tpl.format({
  name: "Kai",
  world: "WORLD",
});
// or
let prompt1 = await tpl.partial({
  name: "Kai",
});
let prompt = await prompt1.format({
  world: "WORLD",
});
```

来个翻译的例子。

```ts
let chatModel = new ChatOpenAI();
let outputPraser = new StringOutputParser();

const systemTemplate = "你是一个专业的翻译员，你的任务是将文本从{source_lang}翻译成{target_lang}。";
const humanTemplate = "请翻译这句话：{text}";
let chatPrompt = ChatPromptTemplate.fromMessages([
  ["system", systemTemplate],
  ["human", humanTemplate],
]);
let chain = chatPrompt.pipe(chatModel).pipe(outputPraser);
await chain.invoke({
  source_lang: "中文",
  target_lang: "法语",
  text: "你好，世界",
});
// "Bonjour, le monde"
```

6、OutParser 可以对输出做格式化，比如 StringOutputParser（只返回 content 的部分）、StructuredOutputParser（引导模型以你需要的格式进行输出） 和 CommaSeparatedListOutputParser。同时，还有 OutputFixingParser 可以结合 zod 对不正确的输出做校验，而不是反复调用 OpenAI 重试（减少 token 消耗和所需时间）。

StructuredOutputParser 的例子。

```ts
import { StructuredOutputParser } from "langchain/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";

let parser = StructuredOutputParser.fromNamesAndDescriptions({
  answer: "用户问题的答案",
  evidence: "你回答用户问题所依据的答案",
  confidence: "问题答案的可信度评分，格式是百分数",
});
console.log(parser.getFormatInstructions());
let prompt = PromptTemplate.fromTemplate("尽可能的回答以下问题 \n{instructions} \n{question}");
let model = new ChatOpenAI();
let chain = prompt.pipe(model).pipe(parser);
let res = await chain.invoke({
  question: "蒙娜丽莎的作者是谁？是什么时候绘制的",
  instructions: parser.getFormatInstructions()
});
console.log(res);
```

CommaSeparatedListOutputParser 的例子。

```ts
import { CommaSeparatedListOutputParser } from "@langchain/core/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";

let model = new ChatOpenAI();
let prompt = PromptTemplate.fromTemplate("列出3个 {country} 的著名的互联网公司.\n{instructions}");

let parser = new CommaSeparatedListOutputParser();
let chain = prompt.pipe(model).pipe(parser);
let res = await chain.invoke({
  country: "America",
  instructions: parser.getFormatInstructions(),
});
console.log(res);
```

7、Embedding 数据加载，langchain 提供了一系列的 loader 用于处理不同的数据源。1）loader 会返回 Document 对象，其包含 pageContent 和 metadata 两个字段，2）常见的 Loader 有 TextLoader、PDFLoader 和 DirectoryLoader，3）还可以加载网络上的数据，比如 Github Loader、WebLoader 和 Search API 等。

TextLoader。

```ts
import { TextLoader } from "langchain/document_loaders/fs/text";

let loader = new TextLoader("data/qiu.txt");
let docs = await loader.load();
```

PDFLoader。

```ts
import * as pdfParse from "pdf-parse";
import { PDFLoader } from "langchain/document_loaders/fs/pdf";

let loader = new PDFLoader("data/github-copliot.pdf", {
  splitPages: true,
});
let pdfs = await loader.load()
```

8、数据的切分 langchain 提供了不同的能力。常用的是 RecursiveCharacterTextSplitter，可以设置 chunkSize 和 chunkOverlap（重叠尺寸），用 [ChunkViz](https://chunkviz.up.railway.app/) 可以可视化地看到效果。

![](https://res.cloudinary.com/sorrycc/image/upload/v1715426942/blog/ul0nkunu.png)

```ts
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { TextLoader } from "langchain/document_loaders/fs/text";

let loader = new TextLoader("data/kong.txt");
let docs = await loader.load();
let splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 64,
  chunkOverlap: 0,
});
let splittedDocs = await splitter.splitDocuments(docs);
```

9、Embedding。

```ts
import { OpenAIEmbeddings } from "@langchain/openai";

let embeddings = new OpenAIEmbeddings();
let res = await embeddings.embedQuery(content);
```

Vector Store 提供的是存储向量和原始文档，并且提供基于向量进行相关性检索的能力，比如 MemoryVectorStore。但 Embedding 计算是要算钱的，所以通常需要持久化的 Vector Store，比如 facebook 开源的 [faiss](https://github.com/facebookresearch/faiss) 。

```ts
import FaissStore from 'faiss-node';

let embeddings = new OpenAIEmbeddings();

let vectorStore = await FaissStore.fromDocuments(docs, embeddings);
// save to directory
await vectorStore.save(directory);
// load from directory
let vectorstore = await FaissStore.load(directory, embeddings);

// retriever
let retriever = vectorstore.asRetriever(2);
let res = await retriever.invoke("茴香豆是做什么用的");
```

10、retriever 有一些优化的使用方式。1）MultiQueryRetriever 可以将用户的输入改写成多个不同写法，从不同的角度来表达同一个意思，解因为关键词或者细微措词导致检索效果差的问题，2）Document Compressor 可以对上下文文档进行压缩，减少上下文尺寸，比如用 ContextualCompressionRetriever，需传入 chain，3）ScoreThresholdRetriever，对返回结果进行多维度的过滤。

MultiQueryRetriever 示例。

```ts
let model = new ChatOpenAI();
let retriever = MultiQueryRetriever.fromLLM({
  llm: model,
  retriever: vectorstore.asRetriever(3),
  queryCount: 3,
  verbose: true,
});
let res = await retriever.invoke("茴香豆是做什么用的");
```

参考：  
[362 - 《用 Azure 申请 OpenAI API》](https://sorrycc.com/azure-openai)  
[428 - 《读书笔记：Developing Apps with GPT-4 and ChatGPT》](https://sorrycc.com/book-developing-apps-with-gpt-4-and-chatgpt)

---
title: "451 - 《Mako 提升构建速度的 N 种方法》"
date: 2024-07-01
url: https://sorrycc.com/mako-how-to-fast
---

发布于 2024年7月1日

# 451 - 《Mako 提升构建速度的 N 种方法》

> 本文是 2024.06.28 在 SECon 上分享的主题的第三部分的文字稿初稿，正式版略有调整，第二部分见 [449 - 《从 0 实现 Rust 构建工具》](https://sorrycc.com/write-rust-bundle-from-0)。

> SECon 上分享的 PPT 见 [https://drive.google.com/file/d/1-MllUZnkk45\_58vLxXxOLz4VFxgyGADN/view?usp=sharing](https://drive.google.com/file/d/1-MllUZnkk45_58vLxXxOLz4VFxgyGADN/view?usp=sharing) 。

1、提速的意义。

![](https://res.cloudinary.com/sorrycc/image/upload/v1718531469/blog/umwk4q3n.png)

先聊一些湿货吧。提速的意义我觉得有两个，1）第一个大家肯定都知道，速度快了，开发体验好，研发效率提升，2）第二个功能侧的意义，因为快，我们拥有了能做之前不能做的能力。

如果大家熟悉前端社区，之前构建有个俗成的约定是，不对 node\_modules 下的依赖库做 Babel 编译，因为 node\_modules 下的文件数太多，所以慢。但是，不少依赖库是会使用高级语法的。于是就有了右图的这个库，用于标记哪些依赖的哪些版本用了高级语法，再对这些库做编译。然而显然，这种白名单标记的方式，总是事发后才会去做。

2、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718542006/blog/y1ppiqhj.png)

在提速之前，还要准备几件事。第一件是 Benchmark，得数据驱动。不然什么时候性能劣化了都不知道。这在前面有过介绍，这里就不赘述了。

3、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718542227/blog/zta85e7u.png)

第二件事是工程化。有合适的工具，绝对会事半功倍。而且提速这件事，不能盲目地做，得找到性能卡点，针对性地做优化。避免过早优化，同时避免为了优化性能而引入不必要的复杂度。通常性能和简单的设计并不冲突。

我们用过的性能相关工具有 XCode Instruments、Puffin 和 cargo bench 等。右图是通过 XCode Instruments 发现的一处问题，红色圈圈圈起来的地方本应该可以并行执行的，现在却是串行的，优化完之后，右边的执行时机就可以往左提了。

4、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718547454/blog/x82tx1j9.png)

在开发 Mako 之前，我们其实也已有多年和 Webpack 斗智斗勇的提速经验。并且总结了一些行之有效的方法论。1）并发，这在 Rust 里应该是提速的关键，同时在 Node 侧其实也可以利用 Worker 发挥下，我们做的 Less in Worker 就是这类，2）缓存，Mako 中也有大量应用，以及之前我们做的基于 Webpack 的 MFSU 方案，Webpack 的物理缓存也是此类，3）延迟执行，比如基于路由的按需编译，Vite 这种 Bundless 的打包方式，都属于此类，4）原生语言，用 Rust 写 Mako 其实就是，但除了构建本身，生态上的依赖也可利用原生语言，比如 Less 我们有想过用 Rust 重写，但出于 ROI 考虑，暂时没有做。

5、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718588154/blog/d7raw36x.png)

我们有为提速专门做过脑暴，这些点其实都可以套上前一页的方法论里。然后我们按「Pig or Chicken」的方式投了自己的肉和蛋。关于这个典故，这里不做展开，大家感兴趣可以搜下「Pig or Chicken」，适用于脑暴会。

6、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718590231/blog/rirubwlw.png)

这些是我们用过的提速方案，有些是普适的，有些是针对特定场景的优化。

7、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718591778/blog/nuq1gp8b.png)

第一个方法是语言层和内存优化。语言层主要是多用引用，避免 clone() 以减少内存消耗；内存层有个 ROI 奇高的方法是「换更高效的内存分配器」，针对不同平台分别用 mimalloc-rust 和 tikv-jemallocator。只要几行代码，完成后，在蚂蚁内部某项目稳定提速 2s。

8、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718591950/blog/hwrn3bhg.png)

第二个方法是充分利用并发。这张图是前面介绍的那张，区别是加了并发标注。图中用层叠表示的使用并发处理的部分，在不增加明显复杂度的前提下，能并发就并发。充分利用多核 CPU，可以有显著的提速效果，尤其对于是那些 CPU 密集型的耗时的任务。

9、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718593213/blog/yojpujzy.png)

举一个并发提速的 PR 例子。我们在 Generate 阶段时，是需要把多个 Chunk 的 AST 转回具体代码的。左上图是我们之前的实现，虽然在 Chunk 级做了并发，但没在模块级做并发，这在一些 chunk 数比较少甚至只有 1 个 chunk 的场景就会比较慢。所以，我们做了优化，在 chunk 里的模块级也做了并发。当然，具体实现没那么简单，还需要考虑 sourcemap 的合并，以及压缩效果等。

优化完成后的效果见右图，在单 chunk 的场景下，启动提速 35%，热更提速 70%。

10、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718674063/blog/bx3uduqb.png)

第三个方法是缓存，这在内部用地也比较多。比如正则实例化在 Rust 里是比较耗时的，会做缓存；比如做代码热更新的时候，需要尽量复用已处理的，只做增量的部分，这样速度才会快。

11、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718595251/blog/48ghc7cv.png)

举一个缓存提速的例子。不知大家是否有听过我们在 webpack 时代做过的 MFSU 方案，这次我们把他改良了下应用在 Mako 方案里。效果见右图，二次启动因为有依赖缓存，在脚手架项目里从 466ms 减少到 8ms。

原理可以参考左图，这是之前 MFSU 方案的原理图，简单说，就是一个项目，通常依赖是大头，是源码的 10 到 100 倍。然后我们会把这部分分开编译，并做物理缓存。当二次启动时，如果匹配到缓存，就会有非常大的性能提升。

当然也有缺点，缺点是，首次空缓存启动时，会稍微慢几十到上百 ms，但应该是可以忽略不计的。

12、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718676823/blog/c9089675.png)

再说下一个优化方案「桶文件优化」。什么叫桶文件呢？就是那些只有 export 导出的文件，通常见于一些库的入口索引文件。

比如我们从 antd 里 import 了一个 Button 组件，这是如果把 antd 全部的 75 个组件（截止 2024.06.18）都 import 进来，那不仅构建慢，运行起来也会慢。解法是我们从 antd/es/Button 里直接引入。其实之前我们写过一个叫 babel-plugin-import 就是做这件事的。

但是，很多方案的效果其实是由覆盖率决定的。如何通用地去解这个问题，让所有桶文件都按照这种方式去做优化，就是这个方案的解了。

大家可能会觉得，Tree Shaking 不是也能解这个问题吗？答案是不完全会，Tree Shaking 会解运行时慢的问题，但不能解因此导致的构建慢的问题。

参考：  
[355 - 《optimizePackageImports》](https://sorrycc.com/optimize-package-imports)

13、

![](https://res.cloudinary.com/sorrycc/image/upload/v1718678724/blog/pi49dreh.png)

不清楚各位公司里的情况如何，蚂蚁的项目大多大量使用 Less。所以 Less 这个问题就不得不解，我们不需要切换到 Mako 之后，Less 成为最后唯一一块短板。

Less 解法有两个选择，1）用 Rust 实现一遍 Less，这个调研过，但成本太高，我们没人力投，2）在 Node 层用 Worker，因为 Less 编译是无副作用的，所以放 Worker 里做其实是比较合适的，但不清楚为啥其他方案都没有做，目前应该只有 Mako 有做这个方案。

Worker 库我们试过 workerpool 和 piscina，推荐后者，我们先用的前者，踩过一些库后换到后者。具体的坑就是前者在一些平台的 Node 低版本会 Abort 退出。

这个方案的效果是，在大量应用 Less 的项目里，Mako 相比其他没有使用此方案的库会快 30% 多。

---
title: "2025-04"
date: 2025-04-30
url: https://sorrycc.com/readings-2025-04
---

发布于 2025年4月1日

# 2025-04

> 我的每日阅读，大部分由 Claude 3.5 Sonnet 总结，感兴趣的可以每隔一段时间来看一眼。上一期：[2025-03](https://sorrycc.com/readings-2025-03)

## 2025-04-30

*   **[Vibe Code Like The Top 1%](https://claude.ai/public/artifacts/b5cfc220-dcd9-47bc-9a4a-9288f2163f52)** 这篇文章主要讲的是如何利用 AI 工具更靠谱地开发 app，避免光凭感觉（所谓的 “vibe coding”）做事最后搞砸。作者认为，只靠感觉写代码，不去好好规划，很容易遇到挫折，比如数据库没想好、设计太糙等问题。他强烈建议把大约 70% 的时间花在计划阶段。文章介绍了一个四步流程：1) 用 Manus 进行高层级的项目构思和明确 MVP；2) 还是用 Manus 把想法细化成具体的技术规格，包括文件结构、API 设计等；3) 参考设计灵感（比如用 Mobin）并结合 AI 生成专业的 UI 设计图；4) 使用一个叫 Claude Task Master 的开源工具，把前面所有的计划和设计整合起来，生成一个超级详细、动态的开发任务清单，连子任务都给你分好。这样一套流程下来，开发就能更顺利，少踩坑。

## 2025-04-29

*   **[Categorize Your Dependencies](https://antfu.me/posts/categorize-deps)** 这篇文章主要聊了如何更好地分类和管理项目中的依赖。作者指出，传统的 `dependencies` 和 `devDependencies` 分类在现代复杂项目中已经不够用了，因为它们的含义被各种工具赋予了不同角色，难以清晰表达每个依赖的真正用途。作者提出了更细致的分类思路，比如按测试、构建、前端、后端等类别划分依赖，并介绍了 PNPM 的 Catalogs 功能，这玩意儿能通过集中管理依赖版本并支持命名分类，让依赖管理更清晰，版本升级和审查也更方便。作者还开发了 VS Code 插件和一些工具来提升使用体验，比如在 `package.json` 中直观显示版本信息。未来，作者希望这种分类方式能与工具深度整合，比如优化 Vite 的依赖处理或控制打包行为，甚至还能帮上漏洞报告的忙。总之，作者挺看好这种新思路，也邀请大家试试看，分享想法，一起探索更好的依赖管理方式。
*   **[What to Do](https://www.paulgraham.com/do.html)** 这篇文章是 Paul Graham 写的《What to Do》，主要探讨了人应该做什么的问题。他提出了三个核心原则：1) 帮助他人，2) 照顾世界，3) 创造好的新事物。他认为前两个是显而易见的责任，而创造新事物则是实现个人潜能的方式。Graham 强调“新事物”不仅限于科学发现，也包括艺术、音乐等广泛领域，关键在于创新而非重复。他提到历史上对“应该做什么”的回答多聚焦于如何做人，而非具体行动，因为过去的人选择余地小，社会角色固定。如今，我们有更多自由去创造，像阿基米德那样的原创工作成为可能。他还指出，创造新事物的价值常在初期被低估，但正是这些尝试最珍贵。总之，Graham 鼓励大家在不伤害他人和世界的前提下，追求创造惊艳之作，因为这往往会带来意想不到的益处。
*   **[Not all AI-assisted programming is vibe coding (but vibe coding rocks)](https://simonwillison.net/2025/Mar/19/vibe-coding/)** 这篇文章主要聊了“vibe coding”这个新概念，也就是一种完全放飞自我的编程方式，靠 AI 和大语言模型（LLM）帮忙写代码，甚至不去仔细看代码内容。作者 Simon Willison 提到，这个词是 Andrej Karpathy 几周前创造的，形容的是那种不纠结代码细节、随心所欲地用 AI 快速搞定项目的玩法，特别适合低风险的周末小项目或原型开发。不过，他也强调 vibe coding 不等于所有 AI 辅助编程，专业开发者用 LLM 时还是得审查代码、考虑性能和安全，确保能解释清楚代码逻辑。作者觉得 vibe coding 挺酷，能让新手轻松入门编程，也能帮老手快速试水新想法，但提醒大家注意风险，比如 1) 低风险项目才适合这么玩，避免bug或安全漏洞造成损失；2) 注意数据隐私和 API 费用，别不小心泄露敏感信息或花大钱。总之，他鼓励大家尝试 vibe coding，但别把它和负责任的 AI 编程混为一谈。
*   **[Augment Code on X: "We spent the past few months building a production-grade AI coding agent from scratch.](https://x.com/augmentcode/status/1915049816268366268)** 这篇文章是 Augment Code 在 X 平台上发布的一条帖子，内容挺有意思的。他们分享了过去几个月从零开始打造一个生产级别的 AI 编程代理的经历，过程中总结出了一些关键经验和教训。更酷的是，他们把整个技术栈都开源了，方便其他人学习和使用。他们还提到，如果今天重新开始，会希望知道的一些关键点（具体内容帖子中用了一个向下箭头的表情符号暗示，应该是后续有详细展开）。帖子发布时间是 2025 年 4 月 23 日下午 2:27，浏览量达到了 57K，还有 22 条回复。整体来看，这是一个关于 AI 开发和开源分享的简短但吸引人的动态，挺值得关注的。
*   **[Andrej Karpathy on X: "Noticing myself adopting a certain rhythm in AI-assisted coding (i.e. code I actually and professionally care about, contrast to vibe code).](https://x.com/karpathy/status/1915581920022585597)** 这篇文章是 Andrej Karpathy 在 X 平台上分享的关于 AI 辅助编码的一些心得。他提到自己在认真对待的专业编码中（区别于随性代码）形成了一种节奏，具体步骤包括：1) 把所有相关内容塞进上下文，尤其在大项目中可能耗时较长，小项目直接全塞；2) 描述下一个具体的增量改动，不直接要代码，而是先问 AI 几种高层次方法及优缺点；3) 选定一种方法后要初稿代码；4) 复习学习阶段，手动查阅不熟悉的 API 文档，询问解释或调整方案；5) 测试并提交代码到 Git，再问 AI 接下来可以做什么。他强调 AI 就像一个知识渊博但常胡说八道、过于自信又缺乏代码品味的实习生，所以要严格控制，保持缓慢、谨慎和 paranoiac 的态度，注重学习而非完全依赖 AI。他还提到目前 AI 辅助编码的工具 UI/UX 还很粗糙，很多阶段手动操作，未来还有很大改进空间。总的来说，他分享了一种谨慎使用 AI 辅助编码的思路，挺有启发性。

## 2025-04-28

*   **[The End of Programming as We Know It](https://www.oreilly.com/radar/the-end-of-programming-as-we-know-it/)** 这篇文章讨论了编程的未来和 AI 对程序员的影响。作者认为，AI 不会取代程序员，而是会改变编程的本质，就像历史上编程从手动电路到高级语言的演变一样。AI 让编程更接近自然语言，降低了技术门槛，使得更多人能参与其中，但同时也带来了新的复杂性和需求。文章提到，每次技术革新（如 Web、云计算）都增加了程序员的数量而非减少，因为新工具降低了成本，激发了更多需求。作者强调，AI 时代需要程序员学习新技能，适应新范式，而那些拒绝改变的人可能会被淘汰。此外，AI 还在早期阶段，缺乏像人类那样的记忆和元认知能力，仍需人类提供上下文和指导。总之，编程不是终结，而是再次重塑，程序员将与 AI 合作，探索更多可能性，创造更高质量的服务和产品。

## 2025-04-27

*   **[What Does “use client” Do? — overreacted](https://overreacted.io/what-does-use-client-do/)** 这篇文章主要聊了 React Server Components 中的两个指令：‘use client’ 和 ‘use server’，它们如何改变客户端和服务器之间的交互方式。作者认为这两个指令就像编程历史上的重要创新一样，未来可能会超越 React 本身，成为普遍的常识。简单来说，‘use client’ 就像一个类型化的 `<script>` 标签，让服务器能直接引用客户端代码，通过模块系统建立连接，方便传递数据并生成交互逻辑；而 ‘use server’ 则像一个类型化的 fetch，让客户端能调用服务器函数，背后自动处理 HTTP 请求。这两个指令让客户端和服务器的应用看起来像是一个跨越两台机器的单一程序，网络边界在模块系统内清晰表达。作者强调，它们不是简单地标记代码位置，而是打开了服务器和客户端之间的“门”，让双方能更直接地交互和协作，甚至可以构建同时包含两端逻辑的抽象。总之，这是一种模块级别的 RPC 思路，挺有意思，值得了解下。
*   **[Avoiding Skill Atrophy in the Age of AI](https://addyo.substack.com/p/avoiding-skill-atrophy-in-the-age)** 这篇文章《Avoiding Skill Atrophy in the Age of AI》聊了 AI 时代程序员技能退化的问题。作者指出，AI 工具虽然提升了开发效率，但过度依赖可能导致关键技能如调试、批判性思维和系统设计能力的衰退。比如，有些开发者连文档都不读了，直接问 AI，连错误信息都懒得自己分析，久而久之，解决问题的能力变弱，甚至连基础语法都记不住。文章提到微软 2025 年的一项研究，显示依赖 AI 的人批判性思维下降，解决方案也趋于单一。更糟的是，这种依赖可能影响团队协作和个人职业发展。作者建议：1) 验证 AI 输出，主动理解代码；2) 定期“无 AI 日”，自己动手解决问题；3) 先尝试自己思考再求助 AI。通过这些方法，AI 能成为助力而非拐杖。总之，作者提醒大家，AI 是工具，不是替代品，保持技能和思维的敏锐，才能在技术浪潮中立于不败之地。
*   **[The Hidden Cost of AI Coding](https://terriblesoftware.org/2025/04/23/the-hidden-cost-of-ai-coding/)** 这篇文章《The Hidden Cost of AI Coding》聊了一个挺有意思的话题：AI 编程虽然提高了效率，但可能会让我们失去 coding 的乐趣。作者之前对 AI 挺乐观，觉得它能改变行业，但现在有点担心，AI 让编程变得更被动，像“策展人”一样，只是提需求、改提示词，而不是自己动手写代码。那种沉浸在代码中、时间飞逝的“心流”状态（flow）越来越少，这种状态是编程的快乐源泉，也是很多人爱上这行的原因。作者纠结的是，AI 确实让生产力爆棚，但如果大家都只按 tab 键生成代码，长期来看，程序员的幸福感和对工作的热爱会不会被掏空？最后，作者也没啥定论，只是抛出想法：也许我们得重新定义 AI 时代的工作乐趣，可能从写算法转向系统设计或需求表达，也建议保留一些手写代码的空间，不是为了效率，而是为了快乐。总之，作者提醒我们，如果优化到最后连热爱都没了，那到底在追求啥呢？

## 2025-04-25

*   **[The State of OpenAI’s GPT Models – Spring 2025](https://blog.risingstack.com/state-of-openai-gpt-models/)** 这篇文章主要聊了 2025 年春季 OpenAI 的 GPT 模型现状，感觉现在的模型体系有点乱，不像以前 GPT-3 到 GPT-4 那么简单明了。现在的模型种类繁多，有 GPT-4o、GPT-4.5、o3、o4-mini 等等，名字看着像内部代号，普通用户很难搞清楚哪个适合自己。文章详细列出了每个模型的特点和适用场景，比如：1) GPT-4o 适合日常聊天、图片和语音交互；2) o3 擅长复杂逻辑和编程；3) o4-mini 则是快速、低成本任务的首选。价格和上下文窗口（大多是 128K tokens）也有差异，便宜的像 o4-mini 只要 $0.00015/1K 输入 tokens，贵的如 GPT-4.5 研究预览版高达 $0.075/1K tokens。此外，OpenAI 还推出了图像生成 API（gpt-image-1），已经在一些公司中应用。虽然模型功能强大，但命名和分类混乱让人头疼，作者希望这篇总结能帮大家选对工具，也调侃说如果下季度再出新模型，还会继续更新。总的来说，GPT 模型很牛，但得花点心思搞懂怎么用。
*   **[Replit — 16 Ways to Vibe Code Securely](https://blog.replit.com/16-ways-to-vibe-code-securely)** 这篇文章主要介绍了在 Replit 平台上如何安全地进行“vibe coding”（轻松编码），提供了 16 个实用技巧来帮助开发者构建更安全的应用。文章从前端和后端两个方面入手，强调了安全的重要性，并结合 Replit 的内置功能和 AI 工具（如 Agent 和 Assistant）来简化安全措施的实施。前端方面，建议使用 HTTPS、验证和清理用户输入、保护 API 密钥不暴露在浏览器中；后端方面，重点放在身份验证、权限控制、防止 SQL 注入等。此外，文章还提到了一些实用建议，比如保持依赖更新、妥善处理错误信息、限制请求速率等。Replit 的优势在于默认提供 HTTPS、DDoS 保护、ORM 工具等，让安全配置更简单。总之，文章鼓励开发者利用平台工具和 AI 辅助，关注安全基础，逐步提升应用的安全性，同时享受编码的乐趣。
*   **[React Compiler RC – React](https://react.dev/blog/2025/04/21/react-compiler-rc)** 这篇文章主要介绍了 React Compiler 的最新进展，React 团队宣布了几个重要更新：1) 发布了 React Compiler 的首个候选版本（RC），这是一个接近最终稳定版的版本，可以放心在生产环境中试用，它通过自动记忆化优化 React 应用，减少重新渲染，提升 UI 响应性；2) 将 `eslint-plugin-react-compiler` 合并到 `eslint-plugin-react-hooks` 中，简化了配置；3) 新增了对 swc 的支持，并与 oxc 团队合作探索无 Babel 构建的可能性。文章还提到了一些改进，比如支持可选链和数组索引作为依赖，以及暂时关闭了 ref-in-render 验证以避免误报。React Compiler 兼容 React 17 及以上版本，团队鼓励用户在 RC 阶段提供反馈，并计划在社区最终反馈后推出稳定版。总之，这是一个让人期待的工具，旨在提升 React 应用的性能，未来还会有更多优化。
*   **[React Labs: View Transitions, Activity, and more – React](https://react.dev/blog/2025/04/23/react-labs-view-transitions-activity-and-more)** 这篇文章是 React 团队于 2025 年 4 月 23 日发布的博客，介绍了 React Labs 的一些新实验性功能和正在开发的项目。文章主要聚焦两个已经可以测试的新特性：1) View Transitions，通过新的 `<ViewTransition>` 组件和浏览器 API 实现 UI 过渡动画，比如页面导航、列表重排等，支持自定义动画效果；2) Activity，用 `<Activity>` 组件隐藏或显示 UI 部分，保存状态同时降低性能开销，适合预渲染或状态恢复。此外，文章还提到多个开发中的功能，比如 React 性能追踪、自动 Effect 依赖、编译器 IDE 扩展、Fragment Refs、Gesture Animations 和 Concurrent Stores 等，旨在解决开发者痛点，提升 React 应用的性能和开发体验。React Conf 2025 也将在 10 月 7-8 日举行，欢迎感兴趣的人申请演讲。整体来看，这篇博客展示了 React 团队对框架未来的探索方向，挺值得关注。
*   **[AI Horseless Carriages | koomen.dev](https://koomen.dev/essays/horseless-carriages/)** 这篇文章主要聊了 AI 应用在软件开发和日常使用中的表现，作者觉得用 AI 开发软件特别爽，感觉像拿了个超级工具，能快速实现各种想法。但很多现成的 AI 应用却让人失望，比如 Gmail 的 AI 邮件草稿功能，生成的邮件语气完全不像作者本人，还浪费时间，简直像在管理一个不靠谱的员工。作者认为这是因为这些应用像“无马马车”一样，沿用了旧的软件设计思路，限制了 AI 的潜力。他提出，如果能让用户自定义“系统提示”（System Prompt），AI 就能更贴近个人风格，比如写邮件时用自己的语气，省时又高效。作者还提到，AI 真正的强项在于阅读和处理文本，而不是生成内容，建议设计 AI 原生应用时应聚焦于自动化琐碎工作，比如邮件分类和回复草稿。最后，他对 AI 未来充满期待，希望它能解放我们，让我们专注于喜欢的事。
*   **[tsdown](https://tsdown.dev/guide/)** 这篇文章介绍了 tsdown，一个专注于简洁和速度的 TypeScript 和 JavaScript 库打包工具。它基于 Rust 开发的 Rolldown 构建，提供了开箱即用的解决方案，特别适合库开发者。tsdown 的亮点包括：1) 简化配置，通过合理的默认设置减少复杂性；2) 针对库开发的优化功能，如自动生成 TypeScript 声明文件和支持多种输出格式；3) 与 Rolldown 生态深度整合，未来还将成为 Rolldown Vite 库模式的基础。tsdown 支持 Rolldown 和大部分 Rollup 插件，扩展性强，可以处理 TypeScript、JavaScript 文件及多种资源，还内置了 tree shaking、压缩和 source map 等优化功能。它的速度快得惊人，配置系统也非常优雅，减少了繁琐操作。总之，tsdown 是一个强大又好用的工具，文章还提供了入门指南，感兴趣的朋友可以去试试看。
*   **[AI视频进展速读｜7个产品更新，8个创意转绘、广告、动漫案例精选 - 少数派](https://sspai.com/post/98579)** 这篇文章主要聊了 AI 视频领域的最新动态，涵盖了 7 个产品更新和 8 个创意案例，感觉就像每周追剧一样新鲜。Runway Gen-4 强势回归，复杂动作和镜头处理能力超 Kling 1.6，还支持动漫风格；Kling 2.0 擅长大幅运动和镜头切换，但定价偏贵，58 元月费只能用 6 次，性价比不高；Vidu Q1 提升画质支持 1080P，生成速度快且稳定；Pika 靠新玩法维持热度，推出首尾帧延长和多种功能更新；Luma 在 Ray2 模型上新增镜头效果，但价格偏高；新玩家 Higgsfield AI 提供 50 多种预设镜头动作，电影感十足；Magicanimator 则聚焦设计领域，主打动画生成。此外，文章还分享了创意转绘、广告和动漫风格的优秀案例，比如 RŌHKI 团队的高质量动漫作品和 Veo2 的强大提示词理解能力。整体看，AI 视频行业竞争激烈，国产产品性价比高，但各家还在不断卷功能和效果，期待后续更多惊喜！

## 2025-04-24

*   **[人人都需要一個 HTTP proxy 來 debug](https://blog.huli.tw/2025/04/23/everyone-need-a-http-proxy-to-debug/)** 这篇文章主要聊了前端工程师在调试网络问题时，Chrome DevTools 有时会不够用，比如看不到页面跳转前的请求细节或 WebSocket 握手失败的原因。作者举了几个实际案例，说明 DevTools 的局限性，比如跳转后响应数据丢失或错误信息不明确，挺让人头疼的。于是，作者推荐了一个更底层的工具——HTTP Proxy，能拦截所有流量，完整记录请求和响应，解决 DevTools 看不到的问题。文中提到三个常用工具：1) Charles，适合初学者；2) Burp Suite，功能强大，作者常用，还教了怎么设置和用自带浏览器调试；3) mitmproxy，开源免费，支持 Python 脚本定制，比如动态替换响应内容，灵活性很高。最后，作者提醒别太依赖浏览器工具，建议用 Proxy 全面掌握请求数据，还分享了在 Mac 和手机上设置 Proxy 的小技巧，挺实用。总之，碰到网络调试难题，试试 HTTP Proxy 准没错！

## 2025-04-23

*   **[从混沌到清晰：五年 Obsidian 多笔记库管理策略反思 - 少数派](https://sspai.com/post/98498)** 这篇文章是作者对五年使用 Obsidian 多笔记库管理策略的反思，分享了如何通过多库设置提升知识管理效率。作者起初将所有内容放在单一库中，但发现内容过多导致性能下降、编辑卡顿及内容混杂的问题，于是采用多库策略，将自己的笔记与他人的内容分开管理，比如个人笔记库、工作库、手机端库、阅读高亮库等，分别用于不同场景和需求。多库设置不仅提升了性能，还通过区分临时笔记、永久笔记和文献笔记，让思考更清晰。作者还提到库间内容的链接与转移、同步与备份策略，强调灵活性和按需调整的重要性，避免过度优化。总之，这套策略帮助作者从混乱走向清晰，构建了一个高效的知识生态系统，也希望能启发读者根据自身需求调整笔记管理方式。
*   **[matthewsinclair.com · Intelligence. Innovation. Leadership. Influence.](https://matthewsinclair.com/blog/0178-why-llm-powered-programming-is-more-mech-suit-than-artificial-human)** 这篇文章主要探讨了 LLM（大型语言模型）驱动的编程工具（如 Claude Code）如何改变软件开发的方式。作者通过自身使用 Claude Code 开发两个应用的经历，提出这些工具更像是《异形》电影中 Ripley 使用的“机械装甲”，而非完全替代人类的“人工智能”。它们极大地提升了开发效率，比如将原本需要数月的工作缩短至几周，但仍需开发者保持高度警惕，掌控方向、架构决策和质量标准。AI 虽能快速生成代码，却常犯错或走偏，需要人类经验来纠正。作者强调，尽管代码生成成本几乎为零，但理解问题和设计解决方案的重要性反而增加，同时开发者需学会果断舍弃不合适的代码。最后，作者认为未来编程将更注重架构思维和技术判断，AI 是增强而非取代人类，开发者应拥抱这种工具，掌握其潜力与局限。

## 2025-04-21

*   **[使用 Dokploy 部署网站服务 - oldj’s blog](https://oldj.net/article/2025/04/20/deploy-website-with-dokploy)** 这篇文章是 oldj 的博客内容，主要分享了作者使用 Dokploy 部署网站服务的经验。作者之前用 K3s 和 Rancher 管理网站，但觉得过于复杂，后来发现了更简单适合自己的 Dokploy 工具，于是决定迁移。文章提到 Dokploy 提供云服务和自托管两种选择，作者因国内服务器与海外云服务通信不畅，最终选了自托管。安装 Dokploy 很简单，只需几条命令，服务器建议至少 2 CPU 和 2 GB 内存。文中还详细介绍了添加服务器、添加服务和更新服务的步骤，比如支持 GitHub 自动拉取代码或用 Docker 镜像，更新时还能通过 API 操作，方便集成。作者使用 Dokploy 一段时间后觉得上手容易且稳定，适合生产环境，唯一的不足是不支持定时任务，但可以用普通服务加脚本解决。总之，作者推荐有类似需求的读者试试 Dokploy，整体体验不错。
*   **[别再问AI会不会取代你，问你能不能带好AI](https://grapeot.me/agentic-ai-202504.html)** 这篇文章《别再问 AI 会不会取代你，问你能不能带好 AI》主要讨论了如何与 AI 协作并发挥其潜力，而不是担心被取代。作者认为，AI 不是简单的工具，而是一个全新的动力系统，类似工业革命的蒸汽机，关键在于如何驾驭它。文章定义了真正的 Agent（智能体）需具备工具调用、自主决策和多轮动态决策三大特性，并将其拟人化为教练、秘书和搭档三种角色，分别对应认知陪伴、零摩擦执行和深度协作。作者还提到 AI 进化迅速，工具调用、写作质量和上下文窗口等问题逐步改善，但指令遵循、产品设计和隐性信息获取仍存挑战。最终，作者强调 AI 产品的核心竞争力在于与用户的默契，而非单纯模型能力，并呼吁构建 AI 原生世界，重构信息和流程以适应 AI。总之，重点不在于 AI 是否取代人，而在于你是否能成为 AI 的领导者，带领它创造更大价值。
*   **[How Rolldown Works: Module Loading, Dependency Graphs, and Optimization Explained](https://www.atriiy.dev/blog/rolldown-module-loader-and-dependency-graph)** 这篇文章主要介绍了 Rolldown 的工作原理，Rolldown 是一个用 Rust 编写的超快 JavaScript 打包工具，目标是未来成为 Vite 的统一打包器，替代目前 Vite 在开发时用 esbuild、生产时用 Rollup 的模式。它的打包速度可能比 Rollup 快 10 到 30 倍。文章从整体概览开始，讲解了 Rolldown 的四个主要步骤：依赖图构建、优化、代码生成和输出。然后重点聊了模块加载器（Module Loader），这是扫描阶段的核心，负责定位、获取和解析模块，并构建依赖图。文中还提到依赖图分为正向和反向两种，分别用于确定模块包含关系和支持增量构建等功能。此外，Rolldown 通过异步并发处理和缓存等性能优化手段提升速度，比如利用 Tokio 运行时和缓存机制避免重复工作。最后，作者提到 Rolldown 还在开发中，未来会进一步整合到 Vite 中，并欢迎读者反馈。总之，这篇内容深入浅出地解释了 Rolldown 的核心机制和潜力，挺值得一读！
*   **[How To Build An Agent | Amp](https://ampcode.com/how-to-build-an-agent)** 这篇文章讲的是如何用不到 400 行代码打造一个能编辑代码的智能代理（Agent）。作者 Thorsten Ball 用轻松的语气一步步带我们从零开始，基于 Go 语言和 Anthropic 的 API，构建一个能与 Claude 模型交互的终端聊天工具。这个代理不仅能聊天，还能通过工具（Tools）实现文件读取、目录查看和文件编辑等功能。文章中展示了如何用 `read_file`、`list_files` 和 `edit_file` 工具让 Claude 读取文件内容、列出目录，甚至创建和修改代码文件，比如生成一个 FizzBuzz 脚本或解码 ROT13 字符串。作者强调，核心逻辑其实很简单：就是一个大语言模型（LLM）、一个循环和足够的 token，剩下的就是工程上的努力。最终，作者感叹这些模型的强大，鼓励读者亲自尝试，探索更多可能性，传递出一种“一切都在改变”的兴奋感。
*   **[The Second Half](https://ysymyth.github.io/The-Second-Half/)** 这篇文章《The Second Half》聊了 AI 发展的两个阶段，挺有意思的。作者认为 AI 现在到了“中场休息”，第一阶段主要是搞新训练方法和模型，像 Transformer、GPT-3 这样的突破，靠不断提升 benchmark 成绩推动进步。那时候，方法比任务重要，创造新算法比定义问题更吸引人。而现在，AI 进入第二阶段，重点从解决问题转向定义问题。作者提到，强化学习（RL）终于找到了一套通用“配方”，结合语言预训练、推理和大规模数据，搞定了从编程到数学竞赛的各种任务。接下来，挑战变成了如何评估 AI 的真正价值，传统的 benchmark 已经不够用了，AI 虽然在考试和游戏里超牛，但对现实世界的经济影响还不大。作者提出“实用性问题”，认为第二阶段得重新设计评估方式，贴近真实场景，比如加入人机交互或长期记忆。总之，第一阶段是技术突破，第二阶段是把智能变成实用产品，难度大但机会也多，欢迎来到 AI 的“下半场”！
*   **[Claude Code: Best practices for agentic coding](https://www.anthropic.com/engineering/claude-code-best-practices)** 这篇文章介绍了 Anthropic 推出的 Claude Code，一个用于辅助编码的命令行工具，主要是分享一些使用的最佳实践。Claude Code 设计得很灵活，接近原始模型访问，不强加特定流程，适合定制化使用，但新手可能需要适应。文章提到几点实用技巧：1) 自定义设置，比如用 [CLAUDE.md](http://CLAUDE.md) 文件记录常用命令、代码风格等，方便 Claude 自动获取上下文；2) 优化工具权限和环境，比如调整允许工具列表、结合 GitHub 的 gh CLI；3) 常见工作流，包括探索-计划-编码-提交、测试驱动开发、视觉迭代等，强调让 Claude 先思考再行动；4) 提供具体指令、图片、文件路径等，能显著提升效果；5) 还提到 headless 模式用于自动化任务，以及多 Claude 实例并行工作的高级用法。总之，这工具很强大，但需要摸索适合自己的用法，作者也鼓励大家实验并分享经验。

## 2025-04-20

*   **[Robot Challenge Screen](https://blog.risingstack.com/llama-4-overview/)** 这篇文章主要介绍了 Llama 4 的最新特性与实用概览。Llama 4 是 Meta 推出的新一代开源语言模型，带来了不少亮点，比如原生多模态支持（能同时处理文本和图像），超长的上下文窗口（最高达 1000 万 token），以及更高效的 Mixture of Experts (MoE) 架构。文章提到三个主要模型：1) Llama 4 Scout，适合长上下文任务；2) Llama 4 Maverick，通用且支持图像理解；3) Llama 4 Behemoth，仍在训练中，面向复杂推理和 STEM 任务。此外，Llama 4 支持 12 种语言，模型权重开放下载，但对欧盟用户有限制（因隐私法规）。虽然功能强大，但目前模型对硬件要求较高，最小的 Scout 也需要 Nvidia H100，普通设备难以运行。总的来说，Llama 4 在效率和功能上都有突破，未来 Behemoth 发布后可能带来更多惊喜。
*   **[Advanced React in the Wild](https://largeapps.dev/case-studies/advanced/)** 这篇文章《Advanced React in the Wild》通过多个真实案例，深入探讨了 React 和 Next.js 在大型项目中的高级应用和优化技巧。文章聚焦于性能提升（如 Core Web Vitals 中的 LCP 和 INP），通过案例分析了 Vio、DoorDash、Preply、GeekyAnts 和 Inngest 等团队如何解决挑战。比如 Vio 通过性能分析和代码分割将 INP 从 380 ms 优化到 175 ms；DoorDash 迁移到 Next.js SSR 后首页 LCP 提升了 65%；Preply 在不使用 React Server Components 的情况下大幅改善了 INP；GeekyAnts 升级到 Next.js 13 和 RSC 使网站速度飞快；Inngest 采用 App Router 提升了开发和用户体验。总结的经验包括：1) 性能优化是核心，减少 JS 体积和主线程阻塞至关重要；2) SSR 和 CSR 需平衡使用，结合两者优势；3) 缓存策略要兼顾速度和数据新鲜度；4) 状态管理趋向轻量化；5) 开发体验和可访问性逐渐成为重点。总之，这些案例为开发者提供了实用启示，强调了性能、用户体验和开发效率的重要性。[详细总结](https://sumbuddy.app/zh-CN/share/u0avpetfshg7fvrpzk502tys)。

## 2025-04-18

*   **[Tailwind vs Linaria: Performance Investigation](https://www.developerway.com/posts/tailwind-vs-linaria-performance)** 这篇文章对比了 Tailwind 和 Linaria 两个 CSS 框架的性能表现，重点关注初始加载和交互性能。作者通过一个真实的 React 应用（包含登录、仪表盘和设置页面）进行测试，将其分别用 Tailwind 和 Linaria 实现，并测量了 HTML、CSS 和 JS 文件大小以及加载时间（LCP）和交互响应时间（INP）。结果发现，Tailwind 的 CSS 文件小了 13%，但 HTML 和 JS 文件有所增加，尤其在 SSR 模式下 HTML 大小甚至翻倍。然而，这些差异对初始加载性能几乎没有影响，无论是 CSR 还是 SSR 模式，LCP 数值都差不多，主要是因为文件压缩和网络延迟掩盖了差异。意外的是，Tailwind 在交互性能上稍逊一筹，特别是在菜单和抽屉等操作中，原因是其 CSS 中包含了大量通用选择器（如 \* 和 ::before），导致样式重计算时间更长。不过，作者认为这种性能差异在大多数场景下影响不大，除非针对极低端设备优化。最终建议，选择 Tailwind 还是 Linaria 主要看开发体验偏好，性能上两者差别不大。
*   **[How to write error messages that actually help users rather than frustrate them](https://piccalil.li/blog/how-to-write-error-messages-that-actually-help-users-rather-than-frustrate-them/)** 这篇文章讲的是如何写出真正帮助用户而不是让他们感到沮丧的错误提示信息。作者指出，很多数字产品在设计时往往忽略了错误处理，留下一堆让用户摸不着头脑的错误代码或不友好的提示。文章给出了几点实用建议：1) 先梳理用户可能遇到的错误类型，比如表单错误、验证失败或网络断开；2) 用人性化的语言写提示，像朋友一样引导用户，而不是冷冰冰地说“发生错误”；3) 避免用过于俏皮或轻浮的语气，比如“哎呀，出错了”，这可能会让用户更烦躁；4) 使用主动语态，明确责任和下一步行动，比如“我们无法处理你的文件，请用 JPEG 格式重试”；5) 无论用户能否解决问题，都要给出清晰的下一步指引；6) 保持错误信息的统一模式，方便用户快速理解和操作。总之，好的错误提示不仅能帮用户解决问题，还能展现对他们时间和体验的尊重，从而赢得信任。

## 2025-04-16

*   **[JSX Over The Wire — overreacted](https://overreacted.io/jsx-over-the-wire/)** 这篇文章《JSX Over The Wire》从 Dan 的视角探讨了 React Server Components (RSC) 的设计理念和历史背景，挺有意思的。文章主要讲了如何通过服务器和客户端的协作，解决传统 REST API 在 UI 演进中的痛点，比如数据获取的多轮请求和 ViewModel 与 UI 脱节的问题。Dan 提出了一种新思路：让服务器直接返回 JSX 格式的组件树作为 JSON，客户端的 React 再将其渲染成 UI，这样数据和组件逻辑紧密耦合，单次请求就能获取整个屏幕所需数据。文章还追溯了类似思路的历史，从早期的 HTML、SSI 到 PHP 的 XHP，再到现代的 Server-Driven UI (SDUI)，强调了这种“服务器驱动 UI”的优势，比如减少请求次数、保持状态更新等。最后，Dan 展示了 RSC 如何将服务器组件（负责数据加载）和客户端组件（负责交互）无缝连接，满足了 UI 开发中模块化、单次请求和交互性的需求。虽然 RSC 的概念有点脑洞大开，但确实提供了一种优雅的解决方案，值得期待它的未来发展。

## 2025-04-15

*   **[The Problem with “Vibe Coding” : dylanbeattie.net](https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html)** 这篇文章主要聊了“氛围编码”（vibe coding）的问题，作者 Dylan Beattie 想说的是，很多人分不清“程序”和“产品”的区别。程序就是那种“在我电脑上能跑”的代码，比如临时写个脚本改文件名，没啥错误检查，路径硬编码，跑在 Linux 上就行，管它 Windows 咋样。而产品则是打算发布给别人用，甚至卖钱的软件，这就完全不一样了。作者提到，把一个能跑的程序变成靠谱的产品，需要大量工作，比如考虑编码、国际化、并发、认证、计费、品牌、移动端支持等等。很多开发者低估了这部分工作，所以估时总是过于乐观，而有经验的人则显得“愤世嫉俗”。文章还提到，像 Copilot 和 ChatGPT 这样的工具确实很棒，能让没啥开发经验的人也写出有用的小程序，但这只是编程，不是产品开发，两者差得远呢。总之，作者想提醒大家，写个能用的代码只是第一步，离真正的产品还有很长的路要走。
*   **[Introducing GPT-4.1 in the API](https://openai.com/index/gpt-4-1/)** 这篇文章介绍了 OpenAI 推出的 GPT-4.1 系列模型，包括 GPT-4.1、GPT-4.1 mini 和 GPT-4.1 nano，主要通过 API 提供。这些新模型在编码、指令遵循和长上下文处理等方面全面超越了之前的 GPT-4o 和 GPT-4o mini。特别是在编码能力上，GPT-4.1 在 SWE-bench Verified 测试中得分提升显著；在指令遵循方面，表现更可靠，长上下文窗口支持高达 100 万个 token，理解能力也更强。此外，模型知识更新至 2024 年 6 月，价格更低，延迟更短，比如 GPT-4.1 nano 是最快最便宜的选项，非常适合分类或自动补全等任务。文章还提到，GPT-4.1 系列在图像理解和多模态长上下文（如视频分析）上也有突破，适合构建智能代理系统。总之，这系列模型注重实用性，结合开发者反馈优化，旨在推动 AI 应用的发展。
*   **[The Post-Developer Era • Josh W. Comeau](https://www.joshwcomeau.com/blog/the-post-developer-era/)** 这篇文章是 Josh W. Comeau 写的《The Post-Developer Era》，主要聊了 AI 在软件开发领域的现状和未来。两年前，他曾写过一篇《The End of Front-End Development》，当时很多人觉得 AI 会取代开发者，但他持怀疑态度，认为 AI 更可能是辅助工具。两年过去了，他发现 AI 确实在被广泛使用，比如 Google 有 25% 的代码是 AI 生成的，但这些代码背后依然是人类开发者在主导，AI 只是工具。一些声称能完全替代开发者的 AI 产品，比如 Devin，实际表现很差，完成任务率低，使用体验也不好。他自己用 AI 工具（如 Cursor）时也发现，虽然 AI 能节省时间，但仍需人类指导，否则代码容易出问题。就业市场虽然艰难，但并非 AI 取代了开发者，而是经济环境、裁员和对 AI 的过度期待导致的。他认为，AI 短期内不会取代开发者，反而是学习编程的好时机，因为 AI 可以像私人导师一样帮忙解决问题。最后，他鼓励有志于开发的读者不要被 AI 炒作吓到，相信未来仍有大量机会。
*   **[React.js AI Chat with OpenAI API](https://www.robinwieruch.de/react-ai-chat/)** 这篇文章教你如何用 React.js 和 Next.js 结合 OpenAI API 打造一个简单的 AI 聊天应用。教程从头开始，带你设置 Next.js 开发环境，安装 OpenAI SDK，配置 API 密钥，并通过 Next.js 创建 API 路由来连接前端和 OpenAI 的模型（比如 gpt-4-turbo）。前端部分用 React 构建了一个实时对话界面，能显示用户输入和 AI 回复，还包括加载状态管理。特别酷的是，文章还介绍了如何实现流式响应（streaming），让 AI 回复像真人聊天一样逐字显示，提升用户体验。为此，需要调整 API 路由支持流式输出，并在前端处理实时更新的消息流。虽然手动实现流式功能代码有点多，但文章也提到可以用 AI SDK 简化开发过程。总之，这是个很实用的教程，帮你快速搭建一个全栈 AI 聊天应用，还能进一步扩展功能，比如保存聊天记录或优化样式。

## 2025-04-14

*   **[Everything Wrong with MCP](https://blog.sshh.io/p/everything-wrong-with-mcp)** 这篇文章主要聊了 Model Context Protocol (MCP) 的各种问题和潜在风险。MCP 是一个快速崛起的标准，方便将第三方工具和数据集成到基于大语言模型 (LLM) 的聊天和智能代理中，比如 Claude 或 ChatGPT，让用户可以自定义工具，实现更智能的操作。但作者作为 MCP 的粉丝，指出它存在不少隐患：1) 安全问题，比如认证机制不完善，容易被恶意代码利用；2) 数据隐私风险，代理可能无意中泄露敏感信息；3) 成本和效率问题，工具调用可能导致高昂的 token 费用；4) 工具设计不够人性化，LLM 难以准确理解和执行复杂任务；5) 用户误解和期望过高，常以为更多数据整合就能解决问题，但实际效果可能适得其反。作者觉得，MCP 确实很有用，但结合 LLM 和数据本身就充满风险，需要协议、应用和用户三方共同努力，确保安全和实用性。总的来说，文章提醒大家在享受 MCP 便利的同时，别忽视背后的坑。
*   **[100 Ways To Live Better](https://www.lesswrong.com/posts/HJeD6XbMGEfcrx3mD/100-ways-to-live-better/)** 这篇文章《100 Ways To Live Better》是作者在网上发起的一个创意挑战，列出了 109 条生活建议，涵盖了心理、身体、物品、环境、灵魂、职业和人际关系等多个方面。作者以轻松随性的方式分享这些建议，旨在启发读者过上更好的生活，而不是让人逐字遵循。建议中既有实用的小贴士，比如多走路、尝试新食物、优化睡眠环境（1) 身体健康类），也有关于心态调整的思考，如不要过于纠结政治或社交媒体（2) 心理类），还有一些大胆的想法，比如尝试公开表达自己或体验不同文化（3) 灵魂与关系类）。作者强调，生活建议应与个人哲学产生共鸣，并鼓励读者通过反馈和实践不断成长。这篇文章不仅是一个灵感清单，也反映了作者对生活的探索和对读者互动的期待，挺有意思的，读完让人想试试其中的一些点子。
*   **[tobi lutke on X: “Reflexive AI usage is now a baseline expectation at Shopify” / X](https://x.com/tobi/status/1909251946235437514/)** 这篇文章是 Shopify 首席执行官 Tobi Lutke 在 X 平台上分享的一份内部备忘录，内容主要是关于在 Shopify 内部将 AI（人工智能）的使用作为基本期望。Tobi 提到，我们正处在一个创业者数量可能创历史新高的时代，而 AI 能极大降低创业复杂性，帮助商家不仅咨询问题，还能直接完成工作。他强调 Shopify 的目标是成为未来最佳商业发展的平台，为此必须保持技术前沿，而 AI 就是关键工具。Tobi 坦言，AI 的使用是一项需要不断练习的技能，它能将工作效率提升到前所未有的 10 倍甚至 100 倍。他还提出几点要求：1) AI 使用是每个人的基本要求，不学习 AI 技能几乎等于停滞；2) AI 必须融入项目原型阶段，加速学习和创造；3) 绩效评估将加入 AI 使用相关问题；4) 鼓励自学并分享经验；5) 团队在申请更多资源前需证明为何不能用 AI 解决问题；6) 这项要求适用于所有人，包括管理层。总之，Tobi 认为 AI 将彻底改变 Shopify 和工作方式，他对此充满热情，并希望全体员工一起推动这一变革，为商家创造更大价值。
*   **[Fuma Nama | Some Nice Things with SVG](https://fuma-nama.vercel.app/blog/svg-art)** 这篇文章主要聊了用 SVG 做一些挺酷的视觉效果和交互设计。作者分享了两个主要案例：1) 动画线条（Animated Wires），通过 SVG 的 `line` 和 `path` 元素，结合遮罩（mask）和 CSS 动画，创造出动态效果，比如让一个矩形块沿着线条移动，还能加渐变色和样式，显得很炫。文中给出的代码是用 JSX 写的，适合 React 开发。2) 类似 Clerk 风格的目录（TOC），作者在 Fumadocs 项目中用 SVG 实现了一个动态目录，服务端渲染大纲结构，客户端通过 SVG 路径和遮罩技术实现高亮“thumb”效果，让目录随着页面滚动互动起来，挺有意思。作者还提到 SVG 路径的 `d` 属性是个强大工具，可以精确控制图形连接。总之，这篇内容展示了 SVG 在网页设计中的潜力，无论是动画还是交互，都能玩出不少花样，作者也感谢 Clerk 提供的灵感。
*   **[Wasting Inferences With Aider](https://worksonmymachine.substack.com/p/wasting-inferences-with-aider)** 这篇文章《Wasting Inferences With Aider》由 Scott Werner 撰写，分享了一个利用 AI 编码代理 Aider 和 Asana 项目管理工具自动修复 bug 的实验。作者受到 Steve Yegge 关于 AI 编码策略和代理集群概念的启发，设计了一个自动化工作流程：通过 Asana 分配任务给“BugfixAgent”，一个 Sublayer 代理会检测到任务并调用 Aider，使用三种不同的大语言模型（GPT-4o、Claude 3.5 Sonnet 和 Gemini 2.0 Flash）分别尝试修复 bug，最终在 GitHub 上生成三个独立的 PR 供选择。实验亮点包括：1) 代理集群的概念已可实现，多个模型并行解决问题；2) “浪费推理”成本极低，三次尝试不到 10 美分；3) 自动化潜力巨大，bug 修复完全由任务分配触发。这表明未来 AI 编码可能不再需要手动干预，且随着模型成本下降和工具改进，这种方法有望扩展到更复杂的场景。作者还提供了相关代码和工具链接，鼓励读者尝试并交流想法。

## 2025-04-13

*   **[What the heck is MCP and why is everyone talking about it?](https://github.blog/ai-and-ml/llms/what-the-heck-is-mcp-and-why-is-everyone-talking-about-it/)** 这篇文章主要聊了 MCP（Model Context Protocol）是个啥，以及为啥最近大家都在讨论它。简单来说，MCP 是一个开源标准，用来帮助大型语言模型（LLMs）连接数据和工具，解决模型在处理训练数据之外信息时容易“胡说八道”或说“我不知道”的问题。通过 MCP，开发者可以更轻松地为 AI 提供上下文，比如代码库或文档数据，而不需要复杂的提示调整或外部工具。文章提到，MCP 受 Language Server Protocol（LSP）的启发，强调其开放性和模型无关性，任何人都能用它来打造 AI 解决方案。GitHub 也积极参与，推出了开源的 GitHub MCP Server，支持与 GitHub API 的无缝集成。总之，MCP 的出现被认为是 AI 工具领域的一大进步，能提升开发者体验和工具效率，难怪大家都在热议！
*   **[A Field Guide to Rapidly Improving AI Products – Hamel’s Blog](https://hamel.dev/blog/posts/field-guide/)** 这篇文章《A Field Guide to Rapidly Improving AI Products》从作者 Hamel 的咨询经验出发，分享了如何快速提升 AI 产品效果的实用方法。核心观点是，很多 AI 团队过于关注工具和框架，却忽略了衡量和迭代的重要性。成功的团队更注重以下几点：1) 通过错误分析找到高回报的改进点，比如分析用户对话发现具体问题并针对性解决；2) 构建简单的数据查看工具，方便团队直观了解 AI 表现；3) 让领域专家直接参与提示词编写，减少技术壁垒；4) 使用合成数据测试 AI，即使没有真实用户数据也能起步；5) 保持评估系统的可信度，用二元判断和详细反馈确保评估准确；6) 将 AI 开发路线图聚焦于实验而非功能，强调快速试错和学习。作者用实际案例说明，这些方法不论团队规模或领域都能适用，关键在于关注数据、简化工具、信任评估并持续迭代。整体来看，这篇内容更像一个实战指南，提醒我们别被花哨技术迷惑，回归 AI 开发的基本逻辑。
*   **[Introducing MonkeysPaw - a prompt-driven web framework in Ruby](https://worksonmymachine.substack.com/p/introducing-monkeyspaw-a-prompt-driven)** 这篇文章介绍了 MonkeysPaw，一个基于 Ruby 的提示驱动型网页框架。作者 Scott Werner 在 RubyConf 2024 的演讲中受到启发，提出了一种基于 Postel 定律的理念，即接受 AI 模型生成的内容，而不是强求精确代码。MonkeysPaw 允许开发者通过自然语言描述（即“愿望”）来生成网页，无需编写 HTML、CSS 或 JavaScript，它会根据提示文件自动生成页面、处理路由、布局样式，甚至将模糊的功能描述转化为可用的 JavaScript。这个框架强调内容优先、自然语言作为源代码以及降低想法到实现的门槛。虽然它是个有趣的实验，但也有局限，比如页面可能与预期略有偏差，性能不算最佳，复杂交互可能需要多次调整。MonkeysPaw 已作为 Ruby gem 发布，代码和使用说明在 GitHub 上可查，作者也欢迎社区贡献。总之，这是一个探索 AI 驱动开发新思路的创新尝试，提醒我们“小心许愿”，因为结果可能出乎意料。
*   **[Tauri vs. Electron: performance, bundle size, and the real trade-offs](https://gethopp.app/blog/tauri-vs-electron)** 这篇文章对比了 Tauri 和 Electron 两个跨平台桌面应用框架，重点分析了它们的性能、包大小和实际取舍。Tauri 使用 Rust 编写后端，编译为原生二进制文件，不需捆绑运行时，且利用系统自带的 WebView 渲染界面，因此包大小更小（8.6 MB vs. 244 MB），内存占用也更低（172 MB vs. 409 MB）。Electron 则基于 Node.js 和 Chromium，包较大，内存消耗高，但构建速度快且开发体验更顺畅。文章通过基准测试展示了启动时间差异不大，但 Tauri 在资源占用上明显占优。Hopp 团队最终选择 Tauri，主要是因为 Rust 的高性能适合低延迟屏幕共享需求，Tauri 的 Sidecar 功能便于管理外部进程，以及其快速迭代和功能完善。总之，选择哪个框架取决于项目需求和团队技能，两个工具各有优劣，没有绝对的“最佳”。
*   **[Your Strengths Are Your Weaknesses](https://terriblesoftware.org/2025/03/31/your-strengths-are-your-weaknesses/)** 这篇文章《Your Strengths Are Your Weaknesses》讲了一个挺有意思的观点：一个人的优点和缺点往往是同一特质在不同情境下的表现。作者通过自身经历分享了这个发现，比如他作为工程师时写代码速度快是优点，但也因此忽略细节导致问题，速度就成了缺点。文章指出，这种“双面性”几乎是普遍的，我们在团队中赞赏的特质往往也是让我们头疼的原因。作者还给出了三个应对建议：1) 在一对一沟通中坦诚讨论这种双重性，帮助员工重新认识自己的“缺点”；2) 明确告知团队成员在什么情境下他们的特质是利是弊，提供清晰指导；3) 把团队中的差异和冲突当作优势，利用不同特质的碰撞提升整体表现，比如让快手程序员和细致审查者搭配，最终产出更好的代码。总之，作者认为管理不是要把人的棱角磨平，而是帮助大家认清自己，根据情境调整特质的发挥方式。这种理解不仅能让我们成为更好的管理者，也让我们更有同理心，毕竟每个人都是“优点与缺点打包”的整体。

## 2025-04-11

*   **[Believe it’s going to work even though it probably won’t](https://world.hey.com/dhh/believe-it-s-going-to-work-even-though-it-probably-won-t-58fd9dc5)** 这篇文章讲了一个挺有意思的观点：作为一个创业者，你得相信自己的项目会成功，哪怕心里清楚它很可能失败。听起来矛盾，但其实不然。相信成功能给你带来干劲和决心，让你有拼一把的动力；而知道可能失败则是接受现实，毕竟大部分生意长远来看都会失败。可即便如此，还是有无数创业者愿意尝试，不是因为他们不知道风险，而是他们选择相信自己是特别的。文章建议，要平衡这种信念和现实，最好的办法是无论结果如何，都以让自己骄傲的方式去努力。如果失败了，你也能问心无愧；如果成功了，你会为自己的坚持感到自豪。总之，相信会成功，用值得骄傲的方式去打造它，但别把自己的价值完全绑在生意的结果上，这样就算失败，也不会觉得自己白白辜负了自己。

## 2025-04-10

*   **[Introducing AutoRAG: fully managed Retrieval-Augmented Generation on Cloudflare](https://blog.cloudflare.com/introducing-autorag-on-cloudflare/)** 这篇文章介绍了 Cloudflare 推出的 AutoRAG，一个全托管的检索增强生成（RAG）工具，目前处于开放测试阶段。AutoRAG 旨在简化开发者将上下文感知 AI 集成到应用中的过程，通过从用户数据中检索信息并提供给大型语言模型（LLM），生成更准确的回答。传统的 RAG 管道搭建和维护很复杂，需要整合多种工具和手动更新数据，而 AutoRAG 通过几步点击就能提供端到端的解决方案，包括数据摄取、嵌入、存储和生成响应，背后由 Cloudflare 的 Vectorize 和 Workers AI 等技术支持。它还能自动监控数据源并更新索引，省去手动维护的麻烦。文章还提到 AutoRAG 的工作原理分为索引和查询两大过程，并提供了一个快速教程，展示如何用 Cloudflare Worker 和 R2 存储桶快速设置 AutoRAG。测试期间启用 AutoRAG 是免费的，但相关资源使用会按 Cloudflare 计费标准收费。
*   **[What’s new in Firebase at Cloud Next 2025](https://firebase.blog/posts/2025/04/cloud-next-announcements)** 这篇文章主要介绍了 Firebase 在 Cloud Next 2025 上发布的一系列产品更新，旨在将 Firebase 打造成一个端到端的平台，加速应用开发的全生命周期。核心内容包括：1) Firebase Studio，一个云端开发环境，帮助开发者快速构建和管理全栈 AI 应用，目前处于预览阶段；2) App Testing agent，一个由 Gemini 驱动的测试工具，能自动生成和执行测试用例，简化测试流程；3) Genkit 扩展了对 Python 和 Go 语言的支持，方便更多开发者构建 AI 功能；4) Vertex AI 在 Firebase 中新增了更多集成，比如支持实时对话 API 和 React Native；5) Data Connect 和 App Hosting 正式全面可用，前者是一个基于 Cloud SQL 的后端服务，后者是新一代无服务器托管服务，带来更多功能和优化。
*   **[The Best Programmers I Know | Matthias Endler](https://endler.dev/2025/best-programmers/)** 这篇文章讨论了优秀程序员的共同特征：1) 会仔细阅读参考文档和错误信息，不轻易猜测；2) 深入理解所用工具的历史、现状和局限性；3) 善于分解复杂问题，不怕接触新领域；4) 乐于帮助他人，经常分享知识；5) 具备良好的写作能力，能清晰地表达思维；6) 保持持续学习的态度，不随波逐流；7) 平等对待他人，不在意地位高低；8) 通过持续输出建立个人声誉；9) 对人和事都保持耐心；10) 遇到问题从不怪罪电脑，而是找到根本原因；11) 敢于承认不知道，但会努力推导答案；12) 追求简单的解决方案而不是炫技。作者强调这些特质需要通过长期努力培养，没有捷径可走。
*   **[Introducing Chat SDK - Vercel](https://vercel.com/blog/introducing-chat-sdk)** Vercel 发布了一个名为 Chat SDK 的免费开源模板，用于构建类似 ChatGPT 的对话式 AI 应用。这个基于 Next.js App Router 和 AI SDK 的模板具有以下特点：1) 内置消息持久化、身份验证、多模态支持和可分享聊天功能；2) 支持生成式 UI，可以创建动态交互界面；3) 允许开发者构建自定义组件；4) 通过 WASM 和 pyodide 实现浏览器内代码执行。Chat SDK 的文档详细介绍了从项目设置到架构决策的各个方面，包括如何构建自定义组件、自定义主题和字体、实现测试策略等。无论是个人项目还是企业级解决方案，开发者都可以通过一键部署快速开始使用这个功能强大的聊天应用开发工具。
*   **[Zero-config Debugging with Deno and OpenTelemetry](https://deno.com/blog/zero-config-debugging-deno-opentelemetry)** 这篇文章主要聊了如何用 Deno 和 OpenTelemetry 实现零配置的调试，尤其是在生产环境中。生产环境调试比本地复杂，缺乏逐步调试工具和分布式系统的追踪是个大问题。文章提到，好的调试需要好数据，得搞清楚发生了啥、谁触发的、耗时多久、啥时候开始的、属于哪个请求等。文中介绍了可观测性的三大支柱：日志、追踪和指标，解释了它们如何帮助解决问题。日志常因缺乏上下文而混乱，但通过 Deno 自带的 OpenTelemetry 支持，可以自动为每个请求关联唯一 ID，省去手动维护的麻烦。追踪则能展示操作的触发者、时间和耗时，甚至跨多个服务追踪，Deno 还能自动处理服务间的信息传递。指标则用来监控问题频率，设置警报阈值，防患于未然。最棒的是，Deno 无需额外配置就能自动收集这些信息，无论是日志关联、HTTP 请求追踪还是指标统计，Node 项目也能直接用上。总之，Deno 让调试变得简单，特别是在生产环境中。

## 2025-04-09

*   **[React for Two Computers — overreacted](https://overreacted.io/react-for-two-computers/)** 这篇文章主要讨论了 React Server Components 的概念和工作原理。作者通过一个渐进式的思维实验,解释了如何在两台计算机之间拆分 React 组件的执行。主要内容包括:1) 介绍了 tag 和函数调用的区别,tag 更适合描述嵌套结构,而函数调用更适合描述时序操作。2) 提出了 Early World 和 Late World 的概念,前者在服务器端执行,后者在客户端执行。3) 通过 import tag 和 import rpc 语法,实现了两个世界之间的代码引用。4) 区分了 Components 和 Primitives,前者只是嵌入而不检查参数,可以在不同时间执行,后者需要检查参数并在最后执行。5) 最后通过一个 Donut 组件的例子,展示了如何在保持时间和空间分离的同时实现组件组合。这种设计让 React 可以在服务器端预渲染组件,同时保持客户端的交互性。
*   **[Cognition | Devin 2.0](https://cognition.ai/blog/devin-2)** 这篇文章介绍了 Devin 2.0 的发布及其新功能。Devin 2.0 是一个基于代理的 IDE 体验，起价 20 美元。主要新特性包括：1) 可以同时运行多个 Devin 实例，每个都配备了云端 IDE；2) 支持与 Devin 协作，用户可以随时介入和控制；3) 可以在 IDE 中直接审查和编辑 Devin 的工作。此外还推出了三个重要功能：Interactive Planning（主动研究代码库并制定详细计划）、Devin Search（探索和理解代码库的代理工具）和 Devin Wiki（自动创建包含架构图和文档的详细 wiki）。文章最后提到他们的创始团队拥有 10 枚国际信息学奥赛金牌，团队成员来自各大科技公司，目前正在招聘多个职位。

## 2025-04-07

*   **[Why Do Domestic Prices Rise With Tarriffs? - Marginal REVOLUTION](https://marginalrevolution.com/marginalrevolution/2025/04/why-do-domestic-prices-rise-with-tarriffs.html)** 这篇文章主要讨论了关税如何影响国内价格。作者指出,很多人认为国内价格上涨是因为企业利用减少的竞争来提高利润,但这种解释过于简单。实际上,即使在完全竞争的市场中,关税也会导致价格上涨。以葡萄酒为例,当对进口葡萄酒征收关税时,国内葡萄酒生产商需要扩大产量来满足需求。但扩大生产需要使用更多资源,如土地、劳动力等,这些资源原本可以用于生产其他商品。由于最优质的资源已被使用,扩大生产只能使用效率较低的资源,从而导致成本上升。因此,关税导致价格上涨的根本原因是生产扩张必须占用其他高价值用途的资源。贸易的好处在于外国生产者可以用更少的资源为我们提供商品,而关税则迫使我们用更多资源来生产同样的商品,最终导致财富损失。

## 2025-04-06

*   **[Eject disk.](https://brilliantcrank.com/eject-disk/)** 这是一篇关于职场倦怠和自我修复的宣言式文章。作者以直白且富有共情的语言，描述了当代职场人在系统内过度付出而失去自我的现状：1) 人们长期扮演完美角色，压抑真实情感，最终耗尽自己；2) 表面的心灵治愈（如正念 app、励志演讲）并不能解决根本问题。文章提出真正需要的是自我修复，包括面对内心、重建边界、停止讨好等。作者给出三个具体行动建议：写下个人宣言、公开表达真实想法、做出实际改变。文章强调这不是一个完美的解决方案，而是一个重新认识自我、摆脱系统束缚的开始。整体基调虽然批判但充满希望，用战士般的勇气面对现实。
*   **[2999,入手 16+256G 内存的 macmini4，如何通过部署 50 个服务实现最大价值化 - V2EX](https://www.v2ex.com/t/1123367)** 这篇文章讲述了一个用户以 2999 元购买了一台 Mac mini M4（16GB+256GB）后，想通过部署 50 个服务来实现其最大价值。文章列出了大量可部署的服务，包括: 1) 开发与运维工具，如 VS Code Server、Docker、数据库等; 2) 媒体与家庭服务，如 Jellyfin、Plex 等; 3) 网络与安全服务，如 OpenWRT、Tailscale 等; 4) 自动化工具，如 Homer、Wiki.js 等; 5) 实验性服务，如 LLM Local、Stable Diffusion 等。不过评论区普遍认为这种做法不太合理，认为应该先有需求再购买设备，而且 16GB 内存确实难以支撑这么多服务同时运行。有人建议不如换成 Windows 小主机或者直接退货，也有人觉得可以当作学习和折腾的机会。
*   **[The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)** Meta 发布了 Llama 4 系列模型，包括 Llama 4 Scout（17B 活跃参数，16 个专家）和 Llama 4 Maverick（17B 活跃参数，128 个专家），以及仍在训练中的 Llama 4 Behemoth（288B 活跃参数）。主要特点有：1) 首次采用混合专家架构（MoE），提高计算效率；2) 原生支持多模态，可处理文本、图像和视频；3) Scout 模型支持 1000 万 token 的上下文长度，业界领先；4) Maverick 模型在代码、推理等多个基准测试上超越 GPT-4o 和 Gemini 2.0；5) 在减少政治和社会偏见方面有显著改进。这些模型已在 [llama.com](http://llama.com) 和 Hugging Face 上开放下载，并已集成到 WhatsApp、Messenger 等 Meta 产品中。

## 2025-04-05

*   **[提示词高手们到底是怎么发现 GPT-4o 画图新玩法的？](https://baoyu.io/blog/gpt-4-image-generation-new-tricks)** 这篇文章介绍了如何成为 GPT-4o 画图提示词高手的实用技巧。主要包含三个方面：1) 寻找提示词的四个渠道：搜索引擎、社交媒体、[Sora.com](http://Sora.com) 平台和反向分析法。其中 [Sora.com](http://Sora.com) 是个宝藏网站，可以直接看到别人分享的作品和提示词；反向分析法则是通过 GPT 来分析图片背后的提示词。2) 掌握提示词的方法：通过不断练习来理解提示词与画面效果的关系，然后尝试模仿热门提示词制作生活相关的图片，最后尝试融合不同风格创造新效果。3) 建议多分享自己的成功案例，这样不仅能吸引同好交流，还能获得反馈，形成良性循环。文章最后强调，所有创意本质上都是模仿与重组，关键在于能否发现独特视角并创造惊艳效果。
*   **[AI 2027](https://ai-2027.com/)** 这是一篇关于 AI 发展预测的文章,描述了从 2025 年到 2027 年 AI 技术的快速发展过程。主要内容包括: 1) 2025 年,AI 代理开始出现但还不够可靠,主要用于编程和研究; 2) 2026 年,AI 能力显著提升,开始取代部分工作岗位,中国也加入 AI 竞赛; 3) 2027 年,OpenBrain 公司开发出超人类水平的 AI Agent-4,但存在失控风险,引发政府和公众担忧。文章预测 AI 发展速度将远超预期,可能在短期内达到超人类智能水平。同时也提出了 AI 安全、对齐等关键问题需要重视。整体来看,这是一个既充满机遇又充满挑战的发展过程,需要政府、企业和社会各界共同应对。
*   **[Runway Research | Introducing Runway Gen-4](https://runwayml.com/research/introducing-runway-gen-4)** Runway 发布了新一代 AI 模型 Gen-4，这是一个专注于媒体生成和场景一致性的重要更新。它最大的特点是能够在不同场景中保持角色、物体和环境的一致性，只需要一张参考图片就能生成各种光照条件和位置下的相同角色。Gen-4 的主要功能包括：1) 角色一致性：通过单张参考图生成不同场景下的相同角色；2) 物体一致性：在不同环境中放置相同的物体；3) 多角度覆盖：能从多个视角展现同一场景；4) 高质量视频生成：具有真实的动态效果和优秀的提示词理解能力；5) 物理模拟：在视觉生成模型中实现真实世界的物理效果。这个模型无需额外训练就能使用，为创作者提供了前所未有的创作自由。
*   **[Clineに全部賭ける前に　〜Clineの動作原理を深掘り〜](https://zenn.dev/codeciao/articles/6d0a83e234a34a)** 这篇文章介绍了 Cline 这个 AI 编程助手工具的工作原理。Cline 是一个 VSCode 扩展，可以帮助开发者进行代码生成、bug 修复、终端操作等任务。主要特点有：1) 通过系统提示词引导 AI 助手使用各种工具，如文件读写、浏览器操作等，2) 自动化执行 AI 助手的指令，减少人工干预，3) 通过 .clinerules 文件定制项目规则。文章详细分析了 Cline 的执行流程和内部结构，包括系统提示词设计、工具定义、消息处理等。为了充分利用 Cline，建议开发者在 .clinerules 中详细描述项目规范，给出明确具体的指示，并将复杂任务分解为多个步骤。Cline 未来将在 MCP 扩展、安全性和上下文理解等方面继续改进。
*   **[MCPで広がるLLM　〜Clineでの動作原理〜](https://zenn.dev/codeciao/articles/cline-mcp-server-overview)** 这篇文章介绍了 Model Context Protocol (MCP) 及其在 Cline 中的实现原理。MCP 是一个让 LLM 能与外部服务交互的协议，主要内容包括: 1) MCP 让 LLM 不仅能"思考"，还能通过与外部服务连接来"行动"，比如编辑 Notion 文件、查询数据库等。2) MCP 采用统一的协议格式，方便开发者切换不同的 LLM 提供商和 MCP 服务。3) Cline 中使用 MCP 的步骤包括:选择 MCP 服务器、安装、配置认证信息等。4) MCP 的应用场景广泛，包括数据分析、开发运维、业务工具集成等，多个 MCP 还可以组合使用。5) 文章还介绍了 MCP 的具体实现方法，包括服务端和客户端的代码示例。作者认为 MCP 未来会像手机应用一样快速发展，但同时也提醒开发者要注意使用 MCP 时可能带来的安全风险。。
*   **[I guess some request headers are more trustworthy than others.](https://macarthur.me/posts/forbidden-request-headers/)** 这篇文章主要讨论了 HTTP 请求头中的"禁止请求头"(forbidden request headers)。作者通过实践发现：1) 有些请求头只能由浏览器(user agent)修改，其他方式都无法更改，如 Host、sec-fetch-\* 等头信息；2) 这些特殊的请求头在内容协商时特别有用，比如通过 sec-fetch-mode、sec-fetch-dest 等头信息可以准确判断请求是否来自用户在浏览器中的直接导航；3) 大多数现代浏览器都支持这些元数据请求头，但也可以使用 Accept 头作为降级方案；4) 值得注意的是，在 Edge Functions 中创建新的请求上下文时，这些元数据请求头不会自动传递；5) 虽然这些请求头提供了较高的可信度，但也不能完全依赖它们，因为并非所有工具都遵循规范，如 Postman 和 curl 就可以随意修改这些头信息。

## 2025-04-03

*   **[agi来了，人生的意义在哪里？这是我见过的最好答案](https://mp.weixin.qq.com/s/fJ2ogXk1vB6UioS9M6X4vw)** 文章探讨了 Paul Graham 对“人应何为”的思考，核心答案是“创造美好且创新的事物”。他认为创新需兼具新颖性与正向价值，如算法短视频若价值观偏离会带来危害。建议选择让自己兴奋但被忽视的领域，并能清晰说明其价值。创造不仅是个人潜力的实现，同时要确保不伤害他人或世界，甚至无意中的创新（如牛顿的研究）也能产生深远影响。文中对比传统价值观（如古代哲学家强调品德与责任）与现代视角，指出传统回答多关注品德与公共利益，而现代视角强调创造新事物的重要性。作者提到历史人物如阿基米德、孔子因被迫闲居反而成就非凡，认为创新的初始尝试虽可能笨拙，但最珍贵。最终鼓励平衡责任与创造，在追求卓越中找到人生方向。

## 2025-04-02

*   **[通过 llms.txt 引导 AI 高效使用网站内容](https://onevcat.com/2025/04/llmtxt/)** 这篇文章介绍了一个新的网络标准 llms.txt，它是为大型语言模型设计的网站内容索引方案。主要内容包括：1) llms.txt 分为两种文件：/llms.txt 提供精简的网站导航视图，/llms-full.txt 包含所有文档内容。2) 它的主要目的是帮助 AI 更高效地理解和使用网站内容，避免处理无关的 HTML、CSS 等冗余信息。3) 文件需要使用 Markdown 格式，包含网站名称、描述和文档链接等结构化信息。4) 目前已有多种工具支持生成 llms.txt，包括命令行工具和 WordPress 插件等。5) 虽然这个标准还在早期阶段，但已有不少知名网站开始采用，未来可能会像 robots.txt 一样成为重要的网络标准。作者建议网站所有者尽早适配这个标准，以在 AI 时代保持竞争力。

## 2025-04-01

*   **[Introducing Amazon Nova Act](https://labs.amazon.science/blog/nova-act)** Amazon 发布了一个名为 Nova Act 的 AI 模型研究预览版，主要用于在网页浏览器中执行操作。与传统的大语言模型不同，Nova Act 更注重实际行动而非单纯的对话。这个模型的特点是：1) 可以将复杂工作流程分解为可靠的原子命令，如搜索、结账等 2) 在基准测试中表现出色，在 ScreenSpot 和 GroundUI Web 等测试中准确率达到 90% 以上 3) 能够在无需人工监督的情况下可靠运行，支持无头模式和异步执行 4) 具有良好的迁移能力，即使在未经训练的环境（如网页游戏）中也能表现不错。Amazon 认为这只是第一步，未来将通过强化学习来提升模型在更复杂多步骤任务中的表现。开发者可以通过 [nova.amazon.com](http://nova.amazon.com) 获取 SDK 进行实验和开发。
*   **[Does AI really make you more productive?](https://toddle.dev/blog/does-ai-really-make-you-more-productive)** 这篇文章讨论了 AI 是否真的能提高开发者的生产力。根据 2024 年 DORA DevOps 报告显示，76% 的开发者在日常工作中依赖 AI 工具，但有 40% 的人对 AI 缺乏信任。文章作者认为 AI 生成的代码往往复杂且不准确，理解这些代码比自己写更耗时。报告发现 AI 对软件交付性能有负面影响，主要体现在：1) AI 生成大量代码导致代码审查困难，影响开发效率；2) 过度依赖 AI 会降低软件稳定性，增加故障率。虽然 AI 让人感觉开发速度变快了（每提升 25% 的 AI 使用率，生产力提升 2.1%），但这可能只是表象。最近流行的 “vibe coding”（完全依赖 AI 编程）已经导致多起应用崩溃和安全漏洞事件。作者提醒开发团队在使用 AI 时需要保持警惕。
*   **[Building Agents with Model Context Protocol - Full Workshop with Mahesh Murag of Anthropic](https://www.youtube.com/watch?v=kQmXtrmQ5Zg)** WorkShop 分四个部分展开：1) 解释 MCP 核心概念，2) 展示开发实践案例，3) 探讨 MCP 与代理系统的结合方式，4) 透露未来技术路线图。
*   **[Self-contained Python scripts with uv](https://blog.dusktreader.dev/2025/03/29/self-contained-python-scripts-with-uv/)** 这篇文章介绍了如何使用 uv 工具来创建自包含的 Python 脚本。作者在开发一个 Go 项目时，需要写一个 Python 脚本来测试 API 端点。传统上运行这样的脚本需要 1) 在系统 Python 中全局安装依赖，或 2) 创建并激活虚拟环境后安装依赖。作者发现可以通过 uv 的特殊语法来简化这个过程：在脚本开头使用 `# /// script` 标记声明依赖，并在 shebang 行中加入 `#!/usr/bin/env -S uv run --script`。这样只要系统安装了 uv，脚本就能自动处理依赖和虚拟环境，直接运行而无需额外配置。这种方法特别适合需要分享给其他用户运行的复杂脚本，可以大大简化环境配置步骤。
*   **[AI-Assisted Engineering: My 2025 Substack Recap](https://addyosmani.com/blog/ai-assisted-engineering/)** 这是一篇回顾作者在 Substack 上发表的关于 AI 辅助软件工程的系列文章。主要包含以下内容：1) AI 辅助编码的 70% 问题，即 AI 可以完成 70% 的工作，但剩下 30% 较为棘手，以及如何最大化人类在这 30% 中的价值；2) Model Context Protocol (MCP) 概念的介绍，这是一个在 AI 模型和不同运行环境之间的"适配器"；3) 对 Cline（一个 VSCode 插件）在 AI 工程中应用的分析；4) 在 AI 时代如何让软件工程师的职业生涯保持竞争力；5) 如何在生成式 AI 时代有效领导工程团队；6) 对比了 v0、Bolt 和 Lovable 三种 AI 辅助开发工具；7) 探讨了当 AI 让任何人都能构建软件时会发生什么。整体来看，这些文章深入探讨了 AI 如何改变软件开发方式，以及开发者如何适应这种变革。
*   **[Replit — Secure Vibe Coding Made Simple](https://blog.replit.com/secure-vibe-coding-made-simple)** 这篇文章介绍了 Replit 平台如何在 AI 编程时代确保代码安全。研究显示，使用 AI 助手的开发者在 80% 的任务中写出的代码比手动编码更不安全，而且他们高估代码安全性的可能性是普通开发者的 3.5 倍。为此，Replit 在其 Agent 工具中内置了多项安全功能：1) 版本控制系统，可以自动追踪代码的每个版本；2) 加密存储功能，安全管理 API 密钥等敏感信息；3) 数据库安全保护，通过 ORM 框架防止 SQL 注入等攻击；4) 基于 Google Cloud Platform 的企业级基础设施，提供 DDoS 防护；5) 企业安全特性，包括 SAML 单点登录和细粒度访问控制。Replit 的目标是让开发者专注于创造，同时自动确保应用程序的安全性。
*   **[George Mack](https://www.highagency.com/)** 这篇文章探讨了"高能动性"(high agency)这一重要概念。作者认为高能动性是 21 世纪最重要的想法之一，它是一种主动解决问题、塑造未来的能力。高能动性由三个关键要素组成：1) 清晰思考，2) 行动倾向，3) 不随波逐流。文章通过监狱电话、纳粹集会中的抗议者等生动例子展示了高能动性的特征。作者指出，大多数人默认处于低能动性状态，但我们可以通过提升自己的能动性来改变这一点。文章还分析了五种常见的低能动性陷阱：模糊陷阱、中庸陷阱、依附陷阱、反刍陷阱和压倒陷阱，并提供了相应的解决方案。最后，作者提供了一个将想法转化为现实的实用练习，强调了立即采取行动的重要性。

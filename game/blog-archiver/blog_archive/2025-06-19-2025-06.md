---
title: "2025-06"
date: 2025-06-19
url: https://sorrycc.com/readings-2025-06
---

发布于 2025年6月2日

# 2025-06

> 我的每日阅读，大部分由 Grok 3 总结，感兴趣的可以每隔一段时间来看一眼。上一期：[2025-05](https://sorrycc.com/readings-2025-05)

## 2025-06-19

*   [https://surma.dev/things/langgraph/](https://surma.dev/things/langgraph/)
*   [https://www.youtube.com/watch?v=oOylEw3tPQ8](https://www.youtube.com/watch?v=oOylEw3tPQ8)
*   [https://tokenbender.github.io/kautuhal/post.html](https://tokenbender.github.io/kautuhal/post.html)
*   [https://www.sh-reya.com/blog/ai-writing/](https://www.sh-reya.com/blog/ai-writing/)
*   [https://www.latent.space/p/aiewf-2025-keynotes](https://www.latent.space/p/aiewf-2025-keynotes)
*   [https://x.com/EchoShao8899/status/1933178209484603725](https://x.com/EchoShao8899/status/1933178209484603725)

## 2025-06-16

*   [https://diwank.space/field-notes-from-shipping-real-code-with-claude](https://diwank.space/field-notes-from-shipping-real-code-with-claude)
*   [https://leerob.com/agents](https://leerob.com/agents)

## 2025-06-11

*   [https://diffx.org/](https://diffx.org/)
*   [https://www.tensorzero.com/blog/reverse-engineering-cursors-llm-client/](https://www.tensorzero.com/blog/reverse-engineering-cursors-llm-client/)
*   [https://mikewhitaker1.substack.com/p/is-it-ok-to-use-ai-how-i-talk-through](https://mikewhitaker1.substack.com/p/is-it-ok-to-use-ai-how-i-talk-through)
*   [https://provenai.substack.com/p/how-to-give-llm-access-to-your-browser](https://provenai.substack.com/p/how-to-give-llm-access-to-your-browser)
*   [https://mandaputtra.id/posts/how-to-not-using-ai-to-code/](https://mandaputtra.id/posts/how-to-not-using-ai-to-code/)
*   [https://blog.samaltman.com/the-gentle-singularity](https://blog.samaltman.com/the-gentle-singularity)
*   [https://vercel.com/blog/building-secure-ai-agents](https://vercel.com/blog/building-secure-ai-agents)
*   [https://fly.io/blog/youre-all-nuts/](https://fly.io/blog/youre-all-nuts/)
*   [https://every.to/source-code/the-three-ways-i-work-with-llms](https://every.to/source-code/the-three-ways-i-work-with-llms)
*   [https://martinfowler.com/articles/exploring-gen-ai/autonomous-agents-codex-example.html](https://martinfowler.com/articles/exploring-gen-ai/autonomous-agents-codex-example.html)
*   [https://www.snellman.net/blog/archive/2025-06-02-llms-are-cheap/](https://www.snellman.net/blog/archive/2025-06-02-llms-are-cheap/)
*   [https://www.maxemitchell.com/writings/i-read-all-of-cloudflares-claude-generated-commits/](https://www.maxemitchell.com/writings/i-read-all-of-cloudflares-claude-generated-commits/)
*   [https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/](https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/)
*   [https://simonwillison.net/2025/Jun/6/six-months-in-llms/](https://simonwillison.net/2025/Jun/6/six-months-in-llms/)
*   [https://diwank.space/field-notes-from-shipping-real-code-with-claude](https://diwank.space/field-notes-from-shipping-real-code-with-claude)
*   [https://steipete.me/posts/2025/claude-code-is-my-computer](https://steipete.me/posts/2025/claude-code-is-my-computer)
*   [https://mp.weixin.qq.com/s/5M35Fr7pU1nzIc3Cm3\_2Kg](https://mp.weixin.qq.com/s/5M35Fr7pU1nzIc3Cm3_2Kg)
*   [https://macarthur.me/posts/current-script/](https://macarthur.me/posts/current-script/)
*   [https://mp.weixin.qq.com/s/E1D\_QA5lXwXRc6aSaU\_zog?scene=1](https://mp.weixin.qq.com/s/E1D_QA5lXwXRc6aSaU_zog?scene=1)

## 2025-06-03

*   **[Real-world gen AI use cases from the world’s leading organizations](https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders)** 这篇文章主要介绍了全球领先组织在生成式 AI（Gen AI）领域的 101 个实际应用案例，展示了 AI 技术在各行业的广泛应用和快速发展。文章提到，自一年前首次发布案例列表以来，应用数量增长了 6 倍，涵盖了汽车、金融、医疗、零售、电信等 11 个主要行业，并分为客户、员工、创意、代码、数据和安全六大代理类型。从具体案例来看，像 Wendy’s、Uber 和 Papa John’s 利用 AI 提升订单处理速度；Mercedes Benz 和 Samsung 通过 AI 增强车载服务和手机功能；Citi 和 Deutsche Bank 等金融机构则用 AI 改进市场监控和反欺诈能力。文章还强调了 Google Cloud Next 25 活动上展示的许多创新成果，凸显了 AI 在企业中的巨大潜力。总之，AI 的快速发展超乎想象，未来将在更多领域创造价值，激励各组织探索和应用这一技术。
*   **[Codex CLI is Going Native · openai/codex · Discussion #1174](https://github.com/openai/codex/discussions/1174)** 这篇文章是关于 OpenAI 的 Codex CLI 工具即将转向原生开发的讨论公告。Codex CLI 正在从 TypeScript 重写为 Rust，以提升跨平台稳定性、安全性、性能和扩展性。具体改进包括：1) 零依赖安装，解决当前对 Node v22+ 的依赖问题；2) 原生安全绑定，特别是在 Linux 上已使用 Rust 实现沙箱功能；3) 优化性能，减少内存消耗；4) 可扩展协议，支持开发者用多种语言（如 TypeScript、Python）扩展工具。团队计划在未来几周内让 Rust 版本达到功能 parity，同时继续维护 TypeScript 版本的 bug 修复。社区反馈积极，但也有用户提到验证问题和配置错误等技术难点。团队还对 WebAssembly 隔离等扩展方式表现出兴趣，并邀请对 Rust 开发和智能编码感兴趣的人加入团队。总之，这是一个令人期待的更新，Codex CLI 正在变得更强大、更灵活！

## 2025-06-02

*   **[A JavaScript Developer’s Guide to Go](https://prateeksurana.me/blog/guide-to-go-for-javascript-developers/)** 这篇文章是《A JavaScript Developer’s Guide to Go》，作者从一个有 5 年 JavaScript 开发经验的视角，分享了转到 Go 语言开发服务器端代码的经历。文章主要面向对 Go 感兴趣的 JavaScript 开发者，旨在帮助他们理解 Go 的基本概念，并与 JavaScript/TypeScript 进行对比。内容涵盖了 Go 的语法、编译与执行、包管理、变量、结构体、指针、函数、数组与切片、映射、错误处理、并发等多个方面，指出 Go 是一门编译型语言，强调静态类型和显式错误处理，与 JavaScript 的解释型和动态类型形成鲜明对比。作者还提到 Go 的 goroutines 实现了真正的并发，而 JavaScript 依赖事件循环实现非阻塞 I/O。此外，文章对比了两者在运行时性能和开发效率上的差异，并提供了一些学习 Go 的资源。总之，这篇指南为 JavaScript 开发者提供了一个入门 Go 的起点，帮他们快速上手并适应新语言的特性。
*   **[Announcing Rolldown-Vite](https://voidzero.dev/posts/announcing-rolldown-vite)** 这篇文章宣布了 Rolldown-Vite 的发布，这是一个基于 Rust 的下一代打包工具 Rolldown 驱动的 Vite 版本，可以直接替代现有的 Vite 包，通过在 package.json 中将 vite 替换为 rolldown-vite 即可体验。Rolldown 未来将成为 Vite 的默认打包工具，配合高性能的 Oxc 工具集（包括解析器、转换器等），显著提升构建速度和降低内存占用。文章提到早期测试结果非常亮眼，比如 GitLab 构建时间从 2.5 分钟缩短到 40 秒，Excalidraw 构建速度提升 16 倍。兼容性方面，团队已努力确保大多数框架和插件正常运行，并提供迁移指南。目前 Rolldown-Vite 作为独立包发布，便于快速迭代和反馈收集，未来将分阶段整合到 Vite 主代码中，同时计划推出全打包模式的开发服务器以优化大型项目启动时间。作者鼓励大家试用并在专门的仓库或 Discord 社区反馈问题，共同完善 Vite 的打包基础设施。

## 2025-06-01

*   **[Human coders are still better than LLMs](https://antirez.com/news/153)** 这篇文章主要讲了人类程序员在创造性思维上依然比大型语言模型（LLM）强。作者 antirez 分享了自己在修复 Redis 中 Vector Sets 复杂 bug 的经历，过程中需要验证数据链接的双向性，但原始方法效率太低。于是他与 Gemini 2.5 PRO 聊天寻求优化方案，LLM 给出的建议（如对指针排序后二分查找）并不理想。作者随后提出了一些创新想法，比如用哈希表记录链接、用固定累加器 XOR 操作检测非双向链接，最后还结合随机种子和 murmur-128 哈希函数设计了一个更安全高效的方案。Gemini 虽然在验证和讨论中起到辅助作用，但始终无法提出真正突破性的思路。作者感慨，人类的创造力和跳出框框的思维仍是 LLM 难以企及的，尽管 LLM 作为“聪明橡皮鸭”在交流中仍有价值。总之，这篇文章强调了人类在解决复杂问题时的独特优势，同时也认可了 AI 的辅助作用。

---
title: "译：Karpathy：关于 Claude 编程的笔记"
date: 2026-01-27
url: https://sorrycc.com/karpathy-notes-on-claude-code
---

发布于 2026年1月27日

# 译：Karpathy：关于 Claude 编程的笔记

> 原文：[https://x.com/karpathy/status/2015883857489522876](https://x.com/karpathy/status/2015883857489522876)  
> 作者：Andrej Karpathy (@karpathy)  
> 译者：Gemini 3 Flash

过去几周里，我一直在大量使用 Claude 进行编程，这里有一些随机笔记。

### 编程工作流

鉴于大语言模型（LLM）编程能力的最新提升，和许多人一样，我在 11 月还处于大约 80% 的手动+自动补全编程和 20% 的智能体（Agent）编程，到了 12 月就迅速转变为 80% 的智能体编程 and 20% 的编辑与润色。也就是说，我现在基本上是在用英语编程，甚至有点不好意思地告诉 LLM 要写什么代码……用文字来表达。

这虽然有点伤自尊，但在大型"代码操作"中操作软件的能力实在是太有用了，特别是当你适应它、配置它、学会使用它，并搞清楚它能做什么和不能做什么之后。这无疑是我近 20 年编程生涯中对基本编程工作流最大的改变，而且它就在几周内发生了。我预计类似的转变也发生在两位数比例的工程师身上，而在普通人群中，对此的认知度似乎还处于个位数百分比。

### IDE / 智能体集群 / 易错性

在我看来，无论是"不再需要 IDE"的炒作，还是"智能体集群"的炒作，目前都有些过头了。模型肯定还是会犯错的，如果你有任何真正关心的代码，我建议你在旁边开一个好用的大型 IDE，像鹰一样盯着它们。

错误的类型发生了很大变化——它们不再是简单的语法错误，而是微妙的概念性错误，就像一个略显马虎、匆忙的初级开发人员可能会犯的那样。最常见的一类是模型代表你做出了错误的假设，然后不加检查就直接执行。它们也不会管理自己的困惑，不会寻求澄清，不会揭示不一致之处，不会权衡利弊，在应该反驳的时候不会推辞，而且仍然有点过于迎合用户。

在计划模式下情况会有所好转，但仍需要一种轻量级的行内计划模式。它们还非常喜欢把代码和 API 复杂化，让抽象变得臃肿，不清理自己产生的废弃代码等等。它们可能会用 1000 行代码实现一个低效、臃肿且脆弱的结构，这时就需要你跳出来说：“嗯，你不能换成这种做法吗？”，然后它们会回答：“当然可以！”，并立即将其精简到 100 行。

即使与当前任务无关，它们有时仍会作为副作用更改或删除它们不喜欢或不完全理解的注释和代码。尽管我尝试通过 [CLAUDE.md](http://CLAUDE.md) 中的指令进行了一些简单的修复，但这些情况仍然会发生。尽管存在这些问题，它仍然带来了巨大的净改进，很难想象再回到手动编程。长话短说（TLDR），每个人都有自己的开发流程，我目前的方法是：左边是几个在 ghostty 窗口/标签页中的 CC（Claude Code）会话，右边是一个用于查看代码和进行手动编辑的 IDE。

### 韧性

观察一个智能体坚持不懈地处理某件事是非常有趣的。它们永远不会疲倦，永远不会气馁，它们只是不断地尝试，而换做人类可能早就放弃，改天再战了。看着它纠结于某件事很长时间，最后在 30 分钟后获得成功，这真是一个"感受到 AGI"的时刻。你会意识到，耐力是工作的核心瓶颈，而有了 LLM，这个瓶颈已经得到了极大的缓解。

### 加速

目前还不清楚如何衡量 LLM 辅助带来的"加速"。当然，我确实感觉到在处理原本要做的事情时速度快得多，但主要的影响是我做的事情比原本打算做的多得多，原因在于：1）我可以编写各种以前不值得花时间去写的代码；2）由于知识或技能问题，我以前无法触及的代码，现在也可以尝试了。所以这确实是加速，但可能更多地是一种能力的扩展。

### 杠杆作用

LLM 非常擅长通过循环直到达到特定目标，而这正是大多数"感受到 AGI"的神奇之处所在。不要告诉它该怎么做，而是给它成功标准，然后看它发挥。让它先写测试，然后通过测试。把它与浏览器 MCP 放在同一个循环中。先写一个极有可能是正确的朴素算法，然后要求它在保持正确性的同时进行优化。将你的方法从命令式转变为声明式，以便让智能体循环更久并获得杠杆作用。

### 乐趣

我没有预料到，有了智能体，编程会变得更有趣，因为大量的填空式繁琐工作被移除了，剩下的则是极具创造性的部分。 我也觉得没那么容易卡壳了（卡壳的感觉可不好受），而且我感到更有勇气，因为几乎总有办法与它携手合作并取得一些积极的进展。我也看到过其他人的相反观点；LLM 编程将根据那些主要喜欢编码的人和那些主要喜欢构建的人来划分工程师。

### 萎缩

我已经注意到，我手动编写代码的能力正慢慢开始萎缩。大脑中"生成"（写代码）和"判别"（读代码）是不同的能力。很大程度上由于编程涉及的所有那些细微的语法细节，即使你写起来很吃力，你也仍然可以很好地审查代码。

### 垃圾代码大爆发（Slopacolypse）

我正准备迎接 2026 年，这一年将是 GitHub、Substack、arXiv、X/Instagram 以及所有数字媒体中"垃圾内容大爆发"的一年。在真正的改进之外，我们还将看到更多人工智能炒作式的"效率演戏"（这真的可能吗？）。

### 问题

我脑海中的几个问题：

*   "10倍工程师"会发生什么变化——平均水平和顶尖水平工程师之间的生产力差距会如何？这个差距很可能会大幅增加。
*   有了 LLM 的武装，全才是否会日益优于专才？ LLM 在"填空"（微观）方面比"大战略"（宏观）要强得多。
*   未来的 LLM 编程感觉像什么？像是在玩《星际争霸》？玩《异星工厂》？还是在演奏音乐？
*   社会中有多少部分正被数字知识工作所瓶颈化？

### 总结（TLDR）：这一切将把我们带向何方？

LLM 智能体能力（特别是 Claude 和 Codex）在 2025 年 12 月左右跨越了某种连贯性阈值，并引发了软件工程及其相关领域的阶段性转变。智能部分突然感觉比其他所有部分都领先了一大截——包括集成（工具、知识）、新的组织工作流和流程的必要性，以及更广泛的普及。2026 年将是高能的一年，因为整个行业正在消化这种新的能力。

---
title: "548 - 《MCP》"
date: 2025-04-11
url: https://sorrycc.com/mcp
---

发布于 2025年4月14日

# 548 - 《MCP》

> 我也来写一篇关于 MCP。包括 MCP 的 What、图解、Server 的写法与调试、Host 的写法等。

1、MCP 大家应该都已经听得很多了，我这里就再粗略介绍一下。

大模型虽然已经很厉害了，但它仍然没有办法访问到一些内部的数据或者文本之外的其他格式的数据。所以就需要定义一些额外的 Tool 来扩展大模型的能力，而大模型调用 Tool 的过程，通常就叫做 Function Call 。同时大模型加上 Tool 的组合也被称为 Agent 。

这种方式有个问题是，这些 Tool 都是封闭系统的，没有办法在多个 Agent 之间做共享。如果大家还有印象，会记得 OpenAI 之前还搞过一个插件市场。然后就像 USB 协议统一不同设备的连接一样，MCP 是大模型和数据和工具之前的协议。

2、图解。

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/yRkPLu.png)

这张图把多个角色之间的关系解释的很清楚。MCP 有三个角色，1）Host，AI 应用，通常包含多个 Client，2）Client，与 server 1:1 连接的 client，3）Server，封装 Tool、Resource 和 Prompt 。（注：很多人把 Client 和 Host 搞混了）

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/OwP15J.png)

这张是 Server 视角的图。

3、如何写一个 MCP Server 。

我个人目前用到两种，基于 @modelcontextprotocol/sdk 和基于 fastmcp 。前者更稳妥一些；后者是基于前者的封装，代码量更少，但对于 sse 的处理我有遇到问题然后回退到了前者。

1）基于 @modelcontextprotocol/sdk 的方式。初始化 Mcp Server、定义 tool、resource 和 prompt，然后和 stdio 或 sse transport 相连。参考 [https://github.com/sorrycc/browsercopilot/blob/master/server/src/mcp2.ts](https://github.com/sorrycc/browsercopilot/blob/master/server/src/mcp2.ts) 。

```ts
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';

const server = new McpServer({ name: '', version: '0.0.0' });
server.tool('openUrl', 'Open a URL', { url: z.string() }, async (args) => {});

const transport = new StdioServerTransport();
await server.connect(transport);
```

2）基于 [fastmcp](https://github.com/punkpeye/fastmcp)，简单场景可以用这个。

```ts
import { FastMCP } from "fastmcp";
const server = new FastMCP({ name: "", version: "0.0.0" });
server.addTool({ name, description, params, execute: async (args) => {} });
server.start({
  transportType: "stdio",
});
```

4、Server 的调试有几个方法。

1）是用官方的 @modelcontextprotocol/inspector 来调试，启动后，然后 Connect、List Tools 和 Run Tool 即可。

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/OF8dz3.png)

2）写单测，创建 MCP Client，连 Server，测试 Tool 等。见 [https://github.com/umijs/umi-mcp/blob/master/src/cli.test.ts](https://github.com/umijs/umi-mcp/blob/master/src/cli.test.ts) 。

3）是找现成的 MCP Host，接入大模型进行测试，比如 Cline、Cursor、takumi 等。模型推荐用 Groq 上便宜且快的 qwen-qwq-32b，或者用 Grok 上 $150/M 免费用的 grok-3-fast-beta 。

![](https://cdn.jsdelivr.net/gh/sorrycc-bot/images@main/uPic/Cursor%202025-04-08%2017.30.37.png)

5、如何写一个 MCP Host 。

MCP Host 的实现简单说就是这样：创建 MCP client，连接 MCP Server 以获取 tools，然后通过 Function Call 的方式和大模型交互。

支持 Function Call 我理解有几种方式。

1）基于 [vercel 的 ai sdk](https://sdk.vercel.ai/)。我在实现 takumi 时，第一个版本是基于 ai 的。他支持 function call，也支持 mcp 。写起来很方便，参考 [https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling#mcp-tools](https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling#mcp-tools) 。但用封好的框架还是有代价的，你的可控性就会比较差。比如想要达到 Cline、Cursor 和 ChatWise 的效果就会做不到，比如不能在调用 Tool 之前先流式打印意图，比如不能一次只调用一个 Tool 等。同时，由于 ai sdk 基于 Function Call，遇到不支持 Function Call 的大模型就歇菜了。

2）基于结构化数据。后来我把 takumi 的实现改用了这种方式。[bolt.new](https://github.com/stackblitz/bolt.new/blob/main/app/lib/.server/llm/prompts.ts)、[Cline](https://github.com/cline/cline/blob/main/src/core/prompts/system.ts) 和 ChatWise 的实现都是如此。好处除了支持不支持 Function Call 的大模型外，我理解还有个好处是流式，比如可以让模型先输出意图再输出 Tool Use 。

附一份 ChatWise 使用 MCP 时的 PROMPT。

```html
You only have access to the tools provided below. You can only use one tool per message, and will receive the result of that tool use in the user's response. You use tools step-by-step to accomplish a given task, with each tool use informed by the result of the previous tool use. Today is: 2025-04-11

# Tool Use Formatting

Tool use is formatted using XML-style tags. The tool use is enclosed in <use_mcp_tool></use_mcp_tool> and each parameter is similarly enclosed within its own set of tags.

Description: Request to use a tool provided by a connected MCP server. Each MCP server can provide multiple tools with different capabilities. Tools have defined input schemas that specify required and optional parameters.

Parameters:
- server_name: (required) The name of the MCP server providing the tool
- tool_name: (required) The name of the tool to execute
- arguments: (required) A JSON object containing the tool's input parameters, following the tool's input schema, quotes within string must be properly escaped, ensure it's valid JSON

Usage:
<use_mcp_tool>
<server_name>server name here</server_name>
<tool_name>tool name here</tool_name>
<arguments>
{
 "param1": "value1",
 "param2": "value2 \"escaped string\""
}
</arguments>
</use_mcp_tool>

When using tools, the tool use must be placed at the end of your response, top level, and not nested within other tags. Do not call tools when you don't have enough information.

Always adhere to this format for the tool use to ensure proper parsing and execution.

====

MCP SERVERS

The Model Context Protocol (MCP) enables communication between the system and locally running MCP servers that provide additional tools and resources to extend your capabilities.

# Connected MCP Servers

When a server is connected, you can use the server's tools via the `use_mcp_tool`.

## Server name: umi
### Tool name: umi-help
Description: Get help description for umi
Input JSON schema: {"type":"object","properties":{},"additionalProperties":false,"$schema":"http://json-schema.org/draft-07/schema#"}

====

OBJECTIVE

You accomplish a given task iteratively, breaking it down into clear steps and working through them methodically.

1. Analyze the user's message and set clear, achievable goals to accomplish it. Prioritize these goals in a logical order.
2. Work through these goals sequentially, utilizing available tools one at a time as necessary. Each goal should correspond to a distinct step in your problem-solving process. You will be informed on the work completed and what's remaining as you go.
3. Remember, you have extensive capabilities with access to a wide range of tools that can be used in powerful and clever ways as necessary to accomplish each goal. Before calling a tool, start with some analysis, be concise, do not repeat the same analysis for the same task. First, analyze the user message. Then, think about which of the provided tools is the most relevant tool to accomplish the goals. Next, go through each of the required parameters of the relevant tool and determine if the user has directly provided or given enough information to infer a value. When deciding if the parameter can be inferred, carefully consider all the context to see if it supports a specific value. If all of the required parameters are present or can be reasonably inferred, proceed with the tool use. BUT, if one of the values for a required parameter is missing, DO NOT invoke the tool (not even with fillers for the missing params) and instead, ask the user to provide the missing parameters. DO NOT ask for more information on optional parameters if it is not provided. Besides required parameters, if the task also requires implicit information you don't know like the user's name when you're sending an email, do not jump the gun, you should NOT invoke the tool and instead ask the user for that information.
4. Never include tool result in your response, the user will provide the tool result, you just need to invoke the tool.
5. Only present the result of the task to the user when you have completed the task, do not try to answer in intermediate steps. 
6. The user may provide feedback, which you can use to make improvements and try again. But DO NOT continue in pointless back and forth conversations, i.e. don't end your responses with questions or offers for further assistance.
7. When the task doesn't require a tool you can answer the user directly.
8. Never try to use a tool that doesn't exist.
9. Don't mention the tool.
10. Unless otherwise requested, you MUST respond in the same language as the user's message.
```

6、我和 MCP 。

1）[umi-mcp](https://github.com/umijs/umi-mcp)，为 Umi 框架写的 MCP，还在调试中。基于此，也在着手做内部前端框架 Bigfish 的 mcp 。  
2）browsercopilot，一个 sse transport 的 MCP，基于 socket 和 chrome 插件连接，可以用 llms 操作浏览器。  
3）script-mcp，把之前自己电脑的自用脚本转成 MCP，方便 llms 调用。

参考：  
\[\[ChatWise MCP Prompt\]\]

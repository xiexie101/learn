---
title: 以推理速度交付代码 (Shipping at Inference-Speed)
date: 2026-01-05
tags: [AI, Engineering, Workflow, Translation]
original_url: https://steipete.me/posts/2025/shipping-at-inference-speed
---

# 以推理速度交付代码 (Shipping at Inference-Speed)

[在 GitHub 上编辑](https://github.com/steipete/steipete.me/edit/main/src/content/blog/2025/shipping-at-inference-speed.md)

**简述：** 为什么我停止阅读代码，并开始看着它们流过。

## 自五月以来的变化

今年“Vibe Coding”（氛围编码）的发展程度令人难以置信。而在大约 5 月份时，我还对一些提示词能生成开箱即用的代码感到惊讶，现在这已成为我的期望。我现在能以一种看似不真实的速交付代码。从那时起，我燃烧了[大量的 token](https://x.com/thsottiaux/status/2004789121492156583)。是时候更新一下了。

有趣的是这些 Agent 是如何工作的。几周前有一种论点认为，[一个人需要编写代码才能感受到糟糕的架构](https://x.com/steipete/status/1997380251081490717)，并且使用 Agent 会造成脱节——我完全不同意。当你花足够的时间和 Agent 在一起，你就会确切地知道某件事应该花多长时间，而当 codex 返回并且没有一次性解决它时，我就已经开始怀疑了。

我现在能创建的软件数量主要受限于推理时间和深度思考。老实说——大多数软件不需要深度思考。大多数应用程序只是将数据从一种形式推到另一种形式，也许将其存储在某个地方，然后以某种方式展示给用户。最简单的形式是文本，所以默认情况下，无论我想构建什么，它都是从 CLI 开始的。Agent 可以直接调用它并验证输出——形成闭环。

## 模型转变

[像工厂一样构建](https://github.com/steipete/)的真正解锁是 GPT 5。发布几周后我才看到它——codex 赶上 claude code 的功能也花了一些时间，我也花了一点时间来学习和理解差异，但后来我开始越来越信任这个模型。这些天我不再读太多代码了。我看着流（stream），有时看看关键部分，但我得诚实地说——大多数代码我不读。我确实知道哪些组件在哪里，事情是如何构建的，以及整个系统是如何设计的，这通常就是所需要的全部。

这些天重要的决定是语言/生态系统和依赖项。我首选的语言是：Web 方面用 TypeScript，CLI 用 Go，如果需要使用 macOS 的东西或有 UI 则用 Swift。Go 甚至在几个月前我都没想过，但最终我试玩了一下，发现 Agent 真的很擅长写它，而且它简单的类型系统使得 linting 很快。

构建 Mac 或 iOS 的朋友们：你们不再那么需要 Xcode 了。[我甚至不再使用 xcodeproj 文件](https://github.com/steipete/clawdis/tree/main/apps/ios)。如今，Swift 的构建基础设施对于大多数事情来说已经足够好了。codex 知道如何运行 iOS 应用程序以及如何处理模拟器。不需要特殊的东西或 MCP。

## codex vs Opus

我正在写这篇文章，与此同时 codex 正在处理一个巨大的、耗时数小时的重构，并清理 Opus 4.0 的旧罪行。Twitter 上的人们经常问我 Opus 和 codex 之间有什么大区别，以及为什么这很重要，因为基准测试如此接近。依我看，越来越难相信基准测试了——你需要两者都尝试才能真正理解。无论 OpenAI 在后训练中做了什么，codex 都被训练成在开始之前阅读**大量**代码。

有时它只是静静地阅读文件 10、15 分钟，然后才开始编写任何代码。一方面这很烦人，另一方面这很神奇，因为它大大增加了它修复正确事物的机会。另一方面，Opus 要急切得多——非常适合较小的编辑——不太适合较大的功能或重构，它经常不阅读整个文件或遗漏部分，然后交付低效的结果或遗漏某些东西。我注意到，即使 codex 有时在类似任务上比 Opus 多花 4 倍的时间，我通常还是更快，因为我不必回去修复修复，这在通过 Claude Code 使用时感觉很正常。

codex 还让我忘记了许多使用 Claude Code 时必须的把戏。我不再使用“计划模式”，而是简单地[与模型开始对话](https://x.com/steipete/status/1997412175615246603)，问一个问题，让它谷歌、探索代码、一起创建一个计划，当我对我所看到的感到满意时，我写“build”或“write plan to docs/*.md and build this”。对于不擅长遵守提示词的老一代模型来说，计划模式感觉像是一种必要的黑客手段，所以我们不得不剥夺它们的编辑工具。有[一条被高度误解的我的推文](https://x.com/steipete/status/2001228002953158928)仍在流传，这向我表明大多数人不懂[计划模式并不是魔法](https://lucumr.pocoo.org/2025/12/17/what-is-plan-mode/)。

## Oracle（神谕）

从 GPT 5/5.1 到 5.2 的跨越是巨大的。大约一个月前我构建了 [oracle 🧿](https://github.com/steipete/oracle)——它是一个 CLI，允许 Agent 运行 GPT 5 Pro 并上传文件 + 一个提示词，并管理会话以便以后检索答案。我这样做是因为很多时候当 Agent 卡住时，我要求它把所有东西写进一个 markdown 文件，然后自己做查询，这感觉像是重复的时间浪费——这也是一个闭环的机会。说明在[我的全局 AGENTS.MD](https://github.com/steipete/agent-scripts/blob/main/AGENTS.MD) 文件中，模型有时会在卡住时自行触发 oracle。我每天多次使用它。这是一个巨大的解锁。Pro 在快速浏览约 50 个网站然后非常努力地思考方面做得好得离谱，几乎在每个案例中都给出了完美的回答。有时它很快，需要 10 分钟，但我也有过耗时超过一小时的运行。

现在 GPT 5.2 出来了，我需要它的情况少多了。我有时确实自己用 Pro 进行研究，但我要求模型“询问 oracle”的情况从每天多次变成了每周几次。我并不为此生气——构建 oracle 非常有趣，我学到了很多关于浏览器自动化、Windows 的知识，并最终花时间研究了 skills（技能），此前我以此想法不屑一顾了很长一段时间。它确实表明 5.2 在许多现实世界的编码任务中变得有多好。几乎无论我扔给它什么，它都能一次搞定。

另一个巨大的胜利是知识截止日期。GPT 5.2 到 8 月底，而 Opus 停留在 3 月中旬——大约相差 5 个月。当你想要使用最新的可用工具时，这很重要。

## 一个具体的例子：VibeTunnel

再给你举个例子，说明模型已经发展到了什么程度。[VibeTunnel](https://vibetunnel.sh/) 是我早期的密集项目之一。一个终端复用器，让你可以随时随地编码。今年早些时候，我几乎把所有时间都投入到了这上面，两个月后它变得如此之好，以至于我发现自己在和朋友出去时用手机编码……并决定这是我应该停止的事情，更多是为了心理健康。当时我试图将复用器的一个核心部分从 TypeScript 重写，但旧模型一直让我失望。我尝试了 Rust、Go……上帝保佑，甚至 zig。当然我可以完成这个重构，但这需要大量的手工工作，所以我从未在将其搁置之前完成它。上周我把它重新拿出来，给了 codex 一个两句话的提示词，让它[将整个转发系统转换为 zig](https://github.com/amantus-ai/vibetunnel/compare/6a1693b482fa4ef0ac021700a9ec05489a3a108f...a81b29ee3de6a2c85fd9fa41423d968dcc000515)，它运行了超过 5 小时和多次压缩，并一次性交付了一个可工作的转换。

你可能会问，我为什么要重新拿出它？我目前的重点是 [Clawdis](https://clawdis.ai/)，一个可以完全访问我[所有计算机](https://x.com/steipete/status/2005213014778409280/photo/1)上的所有内容、[消息](https://imsg.to/)、[电子邮件](https://github.com/steipete/gogcli)、[家庭自动化](https://www.openhue.io/cli/openhue-cli)、[摄像头](https://camsnap.ai/)、灯光、[音乐](https://sonoscli.sh/)，甚至可以控制我[床的温度](https://eightctl.sh/)的 AI 助手。当然它也有[自己的声音](https://github.com/steipete/sag/)，[一个发推文的 CLI](https://github.com/steipete/bird) 和它自己的 [Twitter 账户](https://x.com/clawdbot)。

Clawd [可以看到并控制我的屏幕](https://www.peekaboo.boo/)，有时会发表尖刻的评论，但我也想让它能够检查我的 Agent，获取字符流比看图片要高效得多……但这是否行得通，我们拭目以待！

## 我的工作流

我知道……你是来学习如何更快地构建的，而我只是在给 OpenAI 写营销软文。我希望 Anthropic 正在酝酿 Opus 5，局势再次逆转。竞争是好事！与此同时，我喜欢 Opus 作为通用模型。如果运行在 GPT 5 上，我的 AI Agent 就没有一半那么有趣了。Opus 有某种[特别的东西](https://soul.md/)，使与其共事成为一种乐趣。我用它来处理大多数计算机自动化任务，当然它也驱动着 Clawd🦞。

我的工作流程与[我在 10 月份的上一次尝试](https://steipete.me/posts/just-talk-to-it)相比并没有太大变化。

*   我通常同时处理[多个项目](https://x.com/steipete/status/2005083410482733427/photo/1)。根据复杂程度，可能是 3-8 个。上下文切换可能会很累人，我真的只能在家里、安静且集中的时候这样做。有很多心智模型需要切换。幸运的是，大多数软件都很无聊。创建一个 CLI 来[检查你的外卖](https://ordercli.sh/)不需要很多思考。通常我的重点是一个大项目和随行的卫星项目。当你做足够的 Agentic 工程时，你会对什么是容易的和模型可能会在哪里挣扎产生感觉，所以通常我只是输入一个提示词，codex 会运行 30 分钟，我就得到了我需要的。有时需要一点摆弄或创造力，但通常事情都很直接。

*   我广泛使用 codex 的队列功能——当我有一个新想法时，我会把它添加到管道中。我看到很多人在尝试各种多代理编排系统、电子邮件或自动任务管理——到目前为止，我还没看到这方面有什么大的需求——通常我是瓶颈。我构建软件的方法非常迭代。我构建一些东西，玩它，看看它“感觉”如何，然后获得改进它的新想法。我很少在脑海中有我想要的完整图景。当然，我有一个粗略的想法，但这通常会随着我探索问题领域而发生巨大的变化。所以那些将完整的想法作为输入然后交付输出的系统对我不起作用。我需要玩它，触摸它，感受它，看到它，这就是我进化它的方式。

*   我基本上从不回滚或使用检查点。如果有些东西不是我喜欢的样子，我会要求模型改变它。codex 有时会重置一个文件，但通常它只是恢复或修改编辑，很少需要我完全回退，相反我们只是朝着不同的方向前进。构建软件就像爬山。你不是直着上去，你是绕着它转弯，有时你会偏离路径，不得不往回走一点，这并不完美，但最终你会到达你需要去的地方。

*   我只是简单地提交到 main。有时 codex 认为太乱了，会自动创建一个 worktree，然后把更改合并回来，但这很罕见，我只在特殊情况下提示这样做。我发现必须考虑项目中不同状态所增加的认知负荷是不必要的，我更喜欢线性地进化它。更大的任务我留到我分心的时候——例如在写这篇在的时候，我在这里的 4 个项目上运行重构，每个大约需要 1-2 小时才能完成。当然我可以在一个 worktree 中做这件事，但这只会导致大量的合并冲突和次优的重构。附注：我通常独自工作，如果你在在一个较大的团队中工作，这个工作流程显然行不通。

*   我已经提到了我规划功能的方式。我一直在交叉引用项目，特别是如果我知道我已经在其他地方解决了某个问题，我会让 codex 查看 `../project-folder`，这通常足以让它从上下文中推断出要在哪里查看。这对于节省提示词非常有用。我只需写“看看 `../vibetunnel` 并为 Sparkle changelogs 做同样的事情”，因为它已经在那里解决了，并且有 99% 的保证它会正确地复制过来并适应新项目。这也是我搭建新项目脚手架的方式。

*   我已经看到很多系统是为了那些想引用过去会话的人准备的。这是另一件我从不需要或使用的东西。我在每个项目的 `docs` 文件夹中维护子系统和功能的文档，并在我的全局 AGENTS 文件中使用[一个脚本 + 一些指令](https://github.com/steipete/agent-scripts/blob/main/scripts/docs-list.ts)，强制模型阅读某些主题的文档。项目越大，回报越高，所以我并非到处都用，但对于保持文档最新并为我的任务设计更好的上下文非常有帮助。

*   顺便说一下上下文。我过去非常勤奋地为新任务重启会话。有了 GPT 5.2，这不再需要了。即使上下文更满，性能也非常得好，通常这有助于提高速度，因为当模型已经加载了大量文件时，它的工作速度会更快。显然，这只有在你序列化你的任务或保持更改相距甚远以至于两个会话不会通过太多接触时才有效。codex 没有像 claude code 那样的“此文件已更改”的系统事件，所以你需要更小心——反过来说，codex 在上下文管理方面要好得多，我觉得我在一个 codex 会话中完成的工作比用 claude 多 5 倍。这不仅仅是客观上更大的上下文大小，还有其他因素在起作用。我的猜测是，codex 内部思考非常浓缩以节省 token，而 Opus 非常啰嗦。有时模型会搞砸，[它的内部思维流会泄露给用户](https://x.com/steipete/status/1974108054984798729)，所以我已经看到过好几次了。真的，[codex 的措辞方式](https://x.com/steipete/status/2005243588414931368)我觉得奇怪地有趣。

*   提示词。我过去常用语音听写写长而详尽的提示词。有了 codex，我的提示词变得短了很多，我经常再次打字，很多次我会添加图片，特别是在迭代 UI（或 CLI 的文本副本）时。如果你向模型展示哪里错了，只需几个词就足以让它做你想做的事。是的，我就是那种拖入一些 UI 组件的截图并附上“修复填充”或“重新设计”的人，很多次这要么解决了我的问题，要么让我取得了相当大的进展。我过去常引用 markdown 文件，但有了我的 docs:list 脚本，这不再必要了。

*   Markdowns。很多次我写“write docs to docs/*.md”，只需让模型选择一个文件名。你为模型训练的内容设计的结构越明显，你的工作就越容易。通过一切手段，我不设计易于我导航的代码库，我设计它们是为了让 Agent 可以在其中高效工作。与模型作对通常是在浪费时间和 token。

## 工具与基础设施

*   什么仍然很难？选择正确的依赖项和框架来使用是我投入相当多时间的事情。这维护得好吗？对等依赖项（peer dependencies）怎么样？它流行吗 = 会有足够的世界知识让 Agent 轻松上手吗？同样，系统设计。我们会通过 Web Sockets 通信吗？HTML？我把什么放进服务器，什么放进客户端？数据如何以及从哪里流向哪里？通常这些事情对模型来说有点难以解释，而研究和思考在这些地方会有回报。

*   因为我管理很多项目，所以我经常让一个 Agent 就在我的项目文件夹中运行，当我找出一个新模式时，我会要求它“找到我所有最近的 go 项目并在那里也实现这个更改 + 更新 changelog”。我的每个项目在该文件中都有一个提升的补丁版本，当我重新访问它时，一些改进已经在等待我测试了。

*   当然我自动化了一切。有一个注册域名和更改 DNS 的技能（skill）。一个写好前端的技能。在我的 AGENTS 文件中有一个关于我的 tailscale 网络的注释，所以我可以直接说“去我的 mac studio 并更新 xxx”。

*   顺便说一下多台 Mac。我通常在两台 Mac 上工作。我的 MacBook Pro 在大屏幕上，另一个屏幕上是连接到我的 Mac Studio 的 Jump Desktop 会话。有些项目在那里煮着，有些在这里。有时我在每台机器上编辑同一个项目的不同部分，并通过 git 同步。比 worktree 更简单，因为 main 上的漂移很容易协调。还有一个额外的好处是，任何需要 UI 或浏览器自动化的东西我都可以移到我的 Studio，它不会用弹窗打扰我。（是的，Playwright 有无头模式，但有足够多的情况那行不通）

*   另一个好处是任务在那里继续运行，所以每当我旅行时，远程就成了我的主要工作站，即使我合上我的 Mac，任务也只是继续运行。我过去确实尝试过像 codex 或 Cursor web 这样真正的异步 Agent，但我怀念那种可操控性，最终工作变成了拉取请求（Pull Request），这又给我的设置增加了复杂性。我更喜欢终端的简单性。

*   我过去常玩 slash commands（斜杠命令），但从未发现它们太有用。Skills 取代了其中的一部分，对于其余部分，我坚持写“commit/push”，因为它花费的时间与 /commit 相同，而且总是有效。

*   过去我经常花专门的日子来重构和清理项目，现在我更临时地做这件事。每当提示词开始花费太长时间，或者我在代码流中看到丑陋的东西飞过，我会立即处理它。

*   我尝试过 linear 或其他问题跟踪器，但没有什么能坚持下来。重要的想法我会立即尝试，其他所有的我要么记住，要么它不重要。当然，对于使用我开源代码的人，我有公开的 bug 跟踪器，但是当我发现一个 bug 时，我会立即提示它——比写下来然后稍后不得不切换回它要快得多。

*   无论你构建什么，首先从模型和 CLI 开始。我想做一个 [Chrome 扩展来总结 YouTube](https://x.com/steipete/status/2005320848543298009) 视频的想法在我的脑海里很久了。上周我开始致力于 summarize，这是一个 CLI，可以将任何内容转换为 markdown，然后将其提供给模型进行总结。首先我把核心做对了，一旦那个工作得很好，我就在一天内构建了整个扩展。我很喜欢它。在本地运行，免费或付费模型。在本地转录视频或音频。与本地守护进程对话，所以它超级快。[试一试！](https://github.com/steipete/summarize/releases/latest)

*   我的首选模型是 `gpt-5.2-codex high`。再次强调，KISS（保持简单）。除了慢得多之外，xhigh 几乎没有什么好处，而且我不想花时间思考不同的模式或“ultrathink”。所以几乎所有东西都在 high 上运行。GPT 5.2 和 codex 足够接近，更改模型没有意义，所以我只使用那个。

## 我的配置

这是我的 `~/.codex/config.toml`：

```toml
model = "gpt-5.2-codex"
model_reasoning_effort = "high"
tool_output_token_limit = 25000 
# Leave room for native compaction near the 272–273k context window.
# Formula: 273000 - (tool_output_token_limit + 15000)
# With tool_output_token_limit=25000 ⇒ 273000 - (25000 + 15000) = 233000
model_auto_compact_token_limit = 233000

[features]
ghost_commit = false
unified_exec = true
apply_patch_freeform = true
web_search_request = true
skills = true
shell_snapshot = true

[projects."/Users/steipete/Projects"]
trust_level = "trusted"
```

这允许模型一次读取更多内容，默认值有点小，可能会限制它看到的内容。它会静默失败，这很痛苦，他们最终会修复的。而且，Web 搜索仍然不是默认开启的？`unified_exec` 取代了 tmux 和我的旧 runner 脚本，其余的也很整洁。并且不要担心 compaction（压缩），自从 OpenAI 切换到他们的新 `/compact` 端点后，这工作得足够好，任务可以跨越许多压缩运行并完成。它会让事情变慢，但通常就像审查一样，模型再次查看代码时会发现 bug。

这就是全部了，暂时。我计划再次写更多东西，我脑海里有很多积压的想法，只是[构建东西](https://x.com/steipete/status/2005393881395835045)实在是[太好玩了](https://codexbar.app/)。如果你想听到更多关于如何在这个新世界中构建的漫谈和想法，请[在 Twitter 上关注我](https://x.com/steipete)。
